# Project: Retinal vessel segmentation

The segmentation of retinal blood vessels from eye fundus images is of great significance for early diagnosis of eye-related diseases such as diabetes and hypertension.

The goal of this project is to read an eye fundus image like the following:
![](https://dlsi.ua.es/~pertusa/tvainput21.png)

And extract the blood vessels as can be seen in the corresponding ground-truth sample:

![](https://dlsi.ua.es/~pertusa/tvagt21.png)

All the images for this project are extracted from the [Drive](https://drive.grand-challenge.org) dataset.

For this task you can use any computer vision technique **except by deep neural networks, that are not allowed in this project**.

## Implementation

To begin with the project, first download from moodle the folder with all the images and upload it to google drive.

Then, import the following libraries (you can add more):



import os
from google.colab import drive
import cv2 as cv

drive.mount('/content/drive')

%matplotlib inline
from matplotlib import pyplot as plt

db_path =  "/content/drive/MyDrive/TVAProject"


Now you should edit the following function to segment the image and return the obtained segmentation. This is only a simple (basic) skeleton that obviously is not performing well. Your project's goal is basically to complete this function. You can read the attached papers in Moodle to get ideas for the segmentation.


def vessel_segmentation(input_image):

    img = cv.imread(input_image, cv.IMREAD_GRAYSCALE)

    # TODO: Here it goes your segmentation algorithm. A basic threholding is shown as example.
    th, segmented_image = cv.threshold(img, 128, 255, cv.THRESH_BINARY)

    return segmented_image





Your project will be evaluated with the Intersection over Union (IoU) metric, commonly used in segmentation tasks. This is the function to read a ground truth image and return the IoU considering your segmented image.





def single_IoU(img_name):

    # Apply segmentation
    input_img = os.path.join(db_path, 'input', img_name)
    obtained = vessel_segmentation(input_img)

    # Path of the target (ground truth) image
    path_target = os.path.join(db_path, 'gt', img_name)
    solution = cv.imread(path_target, cv.IMREAD_GRAYSCALE)

    # Show obtained results
    plt.imshow(obtained, cmap=plt.get_cmap('gray'))
    plt.show()

    # IoU calculation
    intersectionAB = cv.countNonZero(obtained & solution)
    unionAB = cv.countNonZero(obtained | solution)
    score = intersectionAB / unionAB
    print("Image {} - IoU={}".format(path_input, score))

    return score






This is the evaluation method that reads all the images from the input folder and gets the mean IoU for all of them. This is the score of your project, the higher the better.



meanIoU=0

path_input = os.path.join(db_path, 'input')

# List images in input folder
imgs = [f for f in os.listdir(path_input) if f.endswith('.png')]
print(imgs)

# For each image
for img in imgs:
    meanIoU += single_IoU(img)

# Average
meanIoU /= len(imgs)
print("------------------------------------")
print("Mean IoU={}".format(meanIoU))


%%writefile fov_mask.py
from __future__ import annotations

from dataclasses import dataclass
from typing import Dict, Optional, Tuple, Union, Literal

import numpy as np
import cv2 as cv

Array = np.ndarray


@dataclass
class FOVMaskDebug:
    """Optional debug outputs to inspect intermediate steps."""
    green_or_gray: Array
    blurred: Array
    otsu: Array
    candidate_chosen: Array
    after_morph: Array
    largest_cc: Array
    filled: Array
    convex_hull: Array
    ellipse_mask: Array
    final: Array
    chosen_inverted: bool
    scores: Dict[str, float]
    ellipse_used: bool
    ellipse_reason: str


def _to_uint8(gray: Array) -> Array:
    if gray.dtype == np.uint8:
        return gray
    g = gray.astype(np.float32)
    g = g - g.min()
    denom = (g.max() - g.min()) if (g.max() - g.min()) > 1e-6 else 1.0
    return (255.0 * g / denom).clip(0, 255).astype(np.uint8)

def _flatfield_for_otsu(g: Array) -> Array:
    """
    Remove slow illumination gradients (vignetting) so global thresholding
    doesn't 'eat' the dark retinal rim.
    """
    h, w = g.shape[:2]
    sigma = 0.12 * float(min(h, w))  # large blur = illumination field
    bg = cv.GaussianBlur(g, (0, 0), sigmaX=sigma, sigmaY=sigma)

    # flat-field: g / bg
    corr = cv.divide(g, bg, scale=255.0)
    corr = cv.normalize(corr, None, 0, 255, cv.NORM_MINMAX)
    return corr.astype(np.uint8)


def _to_gray_or_green(img: Array) -> Array:
    """
    Convert input (BGR/RGB/GRAY) to a single-channel image.
    For fundus images, green channel usually gives best contrast.
    """
    if img is None:
        raise ValueError("Input image is None.")
    if img.ndim == 2:
        gray = img
    elif img.ndim == 3 and img.shape[2] >= 3:
        # OpenCV loads as BGR by default
        gray = img[:, :, 1]  # green channel
    else:
        raise ValueError(f"Unsupported image shape: {img.shape}")
    return _to_uint8(gray)


def _ensure_odd(k: int) -> int:
    k = int(k)
    if k < 1:
        k = 1
    if k % 2 == 0:
        k += 1
    return k


def _auto_ksizes(h: int, w: int) -> Tuple[int, int]:
    """
    Auto choose morphology kernel sizes based on image diagonal.
    Tuned to be "safe" for common fundus sizes (e.g., DRIVE 768x584).
    """
    diag = float(np.hypot(h, w))
    close_k = _ensure_odd(int(round(diag * 0.035)))  # ~33 for DRIVE
    open_k = _ensure_odd(int(round(diag * 0.012)))   # ~11 for DRIVE
    close_k = max(close_k, 25)
    open_k = max(open_k, 9)
    return close_k, open_k


def _morph_cleanup(mask: Array, close_ksize: int, open_ksize: int) -> Array:
    """Close gaps then open to remove specks."""
    close_ksize = _ensure_odd(close_ksize)
    open_ksize = _ensure_odd(open_ksize)

    close_k = cv.getStructuringElement(cv.MORPH_ELLIPSE, (close_ksize, close_ksize))
    open_k = cv.getStructuringElement(cv.MORPH_ELLIPSE, (open_ksize, open_ksize))

    m = cv.morphologyEx(mask, cv.MORPH_CLOSE, close_k)
    m = cv.morphologyEx(m, cv.MORPH_OPEN, open_k)
    return m


def _largest_connected_component(mask: Array) -> Array:
    """Return a binary mask (0/255) containing only the largest foreground CC."""
    m = (mask > 0).astype(np.uint8)
    num, labels, stats, _ = cv.connectedComponentsWithStats(m, connectivity=8)
    if num <= 1:
        return np.zeros_like(mask, dtype=np.uint8)

    areas = stats[1:, cv.CC_STAT_AREA]
    best_idx = 1 + int(np.argmax(areas))
    out = np.zeros_like(mask, dtype=np.uint8)
    out[labels == best_idx] = 255
    return out


def _fill_holes(mask: Array) -> Array:
    """
    Fill holes inside a binary object using flood-fill on the background.
    Input/Output are 0/255 uint8.
    More robust than using only (0,0) as seed.
    """
    m = (mask > 0).astype(np.uint8) * 255
    h, w = m.shape[:2]
    if h == 0 or w == 0:
        return m

    # find a background seed on the border
    border_coords = []
    border_coords += [(0, x) for x in range(w)]
    border_coords += [(h - 1, x) for x in range(w)]
    border_coords += [(y, 0) for y in range(h)]
    border_coords += [(y, w - 1) for y in range(h)]

    seed = None
    for (yy, xx) in border_coords:
        if m[yy, xx] == 0:
            seed = (xx, yy)  # floodFill uses (x,y)
            break
    if seed is None:
        # mask covers the whole border; nothing to flood-fill safely
        return m

    inv = cv.bitwise_not(m)
    ff = inv.copy()
    flood_mask = np.zeros((h + 2, w + 2), dtype=np.uint8)
    cv.floodFill(ff, flood_mask, seedPoint=seed, newVal=0)

    holes = (ff > 0).astype(np.uint8) * 255
    filled = cv.bitwise_or(m, holes)
    return filled


def _convex_hull(mask: Array) -> Array:
    """Return convex hull of the largest object as 0/255 mask."""
    m = (mask > 0).astype(np.uint8) * 255
    contours, _ = cv.findContours(m, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)
    if not contours:
        return np.zeros_like(m, dtype=np.uint8)

    cnt = max(contours, key=cv.contourArea)
    hull = cv.convexHull(cnt)
    out = np.zeros_like(m, dtype=np.uint8)
    cv.drawContours(out, [hull], -1, 255, thickness=cv.FILLED)
    return out


def _candidate_score(candidate_mask: Array) -> float:
    """
    Score a candidate FOV mask.
    Heuristics (good FOV):
      - large area but not the whole image
      - centered
      - low border contact
      - reasonably compact
    """
    m = (candidate_mask > 0).astype(np.uint8)
    h, w = m.shape[:2]
    area = float(m.sum())
    area_ratio = area / float(h * w)

    if area < 10:
        return -1e9

    border = np.concatenate([m[0, :], m[-1, :], m[:, 0], m[:, -1]])
    border_ratio = float(border.mean())

    ys, xs = np.where(m > 0)
    cy, cx = float(np.mean(ys)), float(np.mean(xs))
    center_dist = np.sqrt((cy - (h / 2.0)) ** 2 + (cx - (w / 2.0)) ** 2)
    center_dist_norm = center_dist / np.sqrt((h / 2.0) ** 2 + (w / 2.0) ** 2)

    circ = 0.0
    m255 = (m * 255).astype(np.uint8)
    contours, _ = cv.findContours(m255, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)
    if contours:
        cnt = max(contours, key=cv.contourArea)
        A = float(cv.contourArea(cnt))
        P = float(cv.arcLength(cnt, True))
        circ = (4.0 * np.pi * A) / (P * P + 1e-6)

    area_penalty = 0.6 if (area_ratio < 0.10 or area_ratio > 0.98) else 0.0

    score = (
        + 1.5 * area_ratio
        - 2.0 * border_ratio
        - 0.8 * center_dist_norm
        + 0.4 * circ
        - area_penalty
    )
    return float(score)


def _fit_ellipse_mask_from_contour(mask: Array, scale: float = 1.02) -> Tuple[Array, bool, str]:
    """
    Fit an ellipse to the outer contour and return an ellipse mask.
    scale > 1 expands ellipse slightly (useful to recover small border bites).
    """
    m = (mask > 0).astype(np.uint8) * 255
    h, w = m.shape[:2]
    contours, _ = cv.findContours(m, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_NONE)
    if not contours:
        return np.zeros_like(m, dtype=np.uint8), False, "no_contours"

    cnt = max(contours, key=cv.contourArea)
    if len(cnt) < 5:
        return m.copy(), False, "too_few_points_for_ellipse"

    (cx, cy), (MA, ma), angle = cv.fitEllipse(cnt)  # widths (full axis lengths)
    rx = max(1, int(round((MA * 0.5) * scale)))
    ry = max(1, int(round((ma * 0.5) * scale)))

    out = np.zeros((h, w), dtype=np.uint8)
    cv.ellipse(out, (int(round(cx)), int(round(cy))), (rx, ry), angle, 0, 360, 255, thickness=cv.FILLED)
    return out, True, "fitEllipse"

def _fit_ellipse_mask_from_ring_edges(
    g: Array,
    mask: Array,
    *,
    scale: float = 1.01,
    ring_width: int = 25,
) -> Tuple[Array, bool, str]:
    """
    Fit ellipse from Canny edges located in a thin ring around the mask border.
    This avoids bias from a truncated (bitten) filled region.
    """
    g = _to_uint8(g)
    m = (mask > 0).astype(np.uint8) * 255
    h, w = m.shape[:2]

    ring_width = max(5, int(ring_width))
    k = _ensure_odd(ring_width)
    se = cv.getStructuringElement(cv.MORPH_ELLIPSE, (k, k))

    dil = cv.dilate(m, se)
    ero = cv.erode(m, se)
    ring = cv.bitwise_and(dil, cv.bitwise_not(ero))  # border band

    # Auto Canny thresholds from median intensity INSIDE the mask
    inside = g[m > 0]
    if inside.size < 50:
        return np.zeros_like(m), False, "ring:too_few_inside_pixels"
    med = float(np.median(inside))
    lower = int(max(0, 0.66 * med))
    upper = int(min(255, 1.33 * med))

    edges = cv.Canny(g, lower, upper)
    edges = cv.bitwise_and(edges, ring)

    ys, xs = np.where(edges > 0)
    if ys.size < 80:
        return np.zeros_like(m), False, f"ring:not_enough_edge_points ({ys.size})"

    pts = np.stack([xs, ys], axis=1).astype(np.int32).reshape(-1, 1, 2)

    # fitEllipse needs >=5 points (we have plenty)
    (cx, cy), (MA, ma), angle = cv.fitEllipse(pts)

    rx = max(1, int(round((MA * 0.5) * scale)))
    ry = max(1, int(round((ma * 0.5) * scale)))

    out = np.zeros((h, w), dtype=np.uint8)
    cv.ellipse(out, (int(round(cx)), int(round(cy))), (rx, ry), angle, 0, 360, 255, thickness=cv.FILLED)
    return out, True, "ring:edge_fitEllipse"



def _should_use_ellipse(mask: Array, min_fill_ratio: float = 0.975) -> Tuple[bool, str]:
    """
    Detect the classic 'straight bite' problem:
    the shape is convex, so convex hull won't help, but area is noticeably below
    the best-fitting enclosing shape.

    We compare mask area vs minimum enclosing circle area.
    If the ratio is too low, it suggests a 'cut' happened.
    """
    m = (mask > 0).astype(np.uint8) * 255
    contours, _ = cv.findContours(m, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)
    if not contours:
        return False, "no_contours"

    cnt = max(contours, key=cv.contourArea)
    A = float(cv.contourArea(cnt))
    if A < 100:
        return False, "tiny_area"

    (x, y), r = cv.minEnclosingCircle(cnt)
    circle_area = float(np.pi * (r * r) + 1e-6)
    fill_ratio = A / circle_area

    if fill_ratio < min_fill_ratio:
        return True, f"low_fill_ratio_vs_enclosing_circle ({fill_ratio:.3f} < {min_fill_ratio:.3f})"
    return False, f"ok_fill_ratio ({fill_ratio:.3f})"


EllipseMode = Literal["off", "auto", "force"]

def _fit_ellipse_mask_from_radial_edges(
    g: Array,
    coarse_mask: Array,
    *,
    scale: float = 1.01,
    n_angles: int = 360,
    smooth_k: int = 9,
) -> Tuple[Array, bool, str]:
    """
    Fit an ellipse using boundary points detected from the ORIGINAL image (g),
    by finding the strongest outward intensity drop along radial rays.
    This is robust when the coarse mask has a 'chord' cut (Otsu/vignetting failure).
    """
    g = _to_uint8(g)
    m = (coarse_mask > 0).astype(np.uint8) * 255
    h, w = m.shape[:2]

    contours, _ = cv.findContours(m, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_NONE)
    if not contours:
        return np.zeros_like(m, dtype=np.uint8), False, "radial:no_contours"

    cnt = max(contours, key=cv.contourArea)
    if cv.contourArea(cnt) < 100:
        return np.zeros_like(m, dtype=np.uint8), False, "radial:tiny_area"

    # Use minEnclosingCircle center as a stable center guess (better than centroid when truncated)
    (cx, cy), r_guess = cv.minEnclosingCircle(cnt)
    cx = float(cx)
    cy = float(cy)
    r_guess = float(r_guess)

    if r_guess < 5:
        cx, cy = (w / 2.0), (h / 2.0)
        r_guess = 0.5 * min(h, w)

    # Smooth kernel for 1D profiles
    smooth_k = max(3, int(smooth_k))
    if smooth_k % 2 == 0:
        smooth_k += 1
    kernel = np.ones(smooth_k, dtype=np.float32) / float(smooth_k)

    pts = []

    for theta in np.linspace(0.0, 2.0 * np.pi, n_angles, endpoint=False):
        dx = float(np.cos(theta))
        dy = float(np.sin(theta))

        # Max radius until image boundary
        r_candidates = []
        if abs(dx) > 1e-6:
            r_candidates.append((0.0 - cx) / dx)
            r_candidates.append(((w - 1.0) - cx) / dx)
        if abs(dy) > 1e-6:
            r_candidates.append((0.0 - cy) / dy)
            r_candidates.append(((h - 1.0) - cy) / dy)

        r_candidates = [rr for rr in r_candidates if rr > 0]
        if not r_candidates:
            continue
        rmax = min(r_candidates)
        if rmax < 5:
            continue

        # Search window around guessed radius
        r_start = int(max(5, 0.55 * r_guess))
        r_end = int(min(rmax - 2, 1.25 * r_guess))
        if r_end <= r_start + 4:
            r_start = 1
            r_end = int(rmax - 2)

        rr = np.arange(r_start, r_end + 1, dtype=np.int32)
        xs = np.clip(np.rint(cx + rr * dx).astype(np.int32), 0, w - 1)
        ys = np.clip(np.rint(cy + rr * dy).astype(np.int32), 0, h - 1)

        prof = g[ys, xs].astype(np.float32)
        if prof.size < 6:
            continue

        # Smooth the profile to reduce vessel/noise spikes
        prof_s = np.convolve(prof, kernel, mode="same")

        # We want the strongest OUTWARD drop: inside(bright) -> outside(dark)
        drops = prof_s[:-1] - prof_s[1:]  # positive when going darker
        idx = int(np.argmax(drops))
        r_edge = int(rr[idx])

        x = int(np.clip(round(cx + r_edge * dx), 0, w - 1))
        y = int(np.clip(round(cy + r_edge * dy), 0, h - 1))
        pts.append([x, y])

    if len(pts) < 5:
        return np.zeros_like(m, dtype=np.uint8), False, "radial:too_few_points"

    pts_np = np.array(pts, dtype=np.int32).reshape(-1, 1, 2)
    (ecx, ecy), (MA, ma), angle = cv.fitEllipse(pts_np)

    rx = max(1, int(round((MA * 0.5) * scale)))
    ry = max(1, int(round((ma * 0.5) * scale)))

    out = np.zeros((h, w), dtype=np.uint8)
    cv.ellipse(
        out,
        (int(round(ecx)), int(round(ecy))),
        (rx, ry),
        angle,
        0,
        360,
        255,
        thickness=cv.FILLED,
    )
    return out, True, "radial:edge_drop_fitEllipse"



def compute_fov_mask(
    img_or_path: Union[str, Array],
    *,
    blur_ksize: int = 7,
    blur_kind: str = "median",     # "median" or "gaussian"
    close_ksize: Optional[int] = None,  # None => auto
    open_ksize: Optional[int] = None,   # None => auto
    do_hole_fill: bool = True,
    do_convex_hull: bool = True,
    ellipse_mode: EllipseMode = "auto",  # off / auto / force
    ellipse_scale: float = 1.02,         # slightly enlarge to recover small bites
    ellipse_min_fill_ratio: float = 0.975,
    return_debug: bool = False,
) -> Union[Array, Tuple[Array, FOVMaskDebug]]:
    """
    Compute a clean binary Field-Of-View (FOV) mask (0/255 uint8) for a fundus image.

    Fixes supported (exactly what we discussed):
      1) stronger closing (auto close/open sizes are bigger by default)
      2) convex hull (optional)
      3) ellipse fitting (robust for convex 'bites' that hull cannot fix)

    Returns:
      mask (uint8 0/255), and optionally debug object.
    """
    # Load if needed
    if isinstance(img_or_path, str):
        img = cv.imread(img_or_path, cv.IMREAD_UNCHANGED)
        if img is None:
            raise FileNotFoundError(f"Could not read image from path: {img_or_path}")
    else:
        img = img_or_path

    g = _to_gray_or_green(img)
    h, w = g.shape[:2]

    # Auto kernel sizes if not provided
    if close_ksize is None or open_ksize is None:
        auto_close, auto_open = _auto_ksizes(h, w)
        if close_ksize is None:
            close_ksize = auto_close
        if open_ksize is None:
            open_ksize = auto_open

    # Blur
    blur_ksize = _ensure_odd(blur_ksize)
    if blur_kind.lower() == "median":
        blurred = cv.medianBlur(g, blur_ksize)
    elif blur_kind.lower() == "gaussian":
        blurred = cv.GaussianBlur(g, (blur_ksize, blur_ksize), 0)
    else:
        raise ValueError("blur_kind must be 'median' or 'gaussian'.")
    g_corr = _flatfield_for_otsu(blurred)
    # Otsu threshold
    _, otsu = cv.threshold(g_corr, 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU)

    # Two candidates: otsu foreground or inverted foreground
    cand_a = otsu
    cand_b = cv.bitwise_not(otsu)

    # Morph cleanup each candidate (this is where close fixes bites)
    cand_a_m = _morph_cleanup(cand_a, close_ksize=close_ksize, open_ksize=open_ksize)
    cand_b_m = _morph_cleanup(cand_b, close_ksize=close_ksize, open_ksize=open_ksize)

    # Keep largest CC
    cand_a_l = _largest_connected_component(cand_a_m)
    cand_b_l = _largest_connected_component(cand_b_m)

    # Score both
    score_a = _candidate_score(cand_a_l)
    score_b = _candidate_score(cand_b_l)

    if score_b > score_a:
        chosen = cand_b_l
        chosen_inverted = True
        scores = {"normal": score_a, "inverted": score_b}
        after_morph = cand_b_m
    else:
        chosen = cand_a_l
        chosen_inverted = False
        scores = {"normal": score_a, "inverted": score_b}
        after_morph = cand_a_m

    filled = _fill_holes(chosen) if do_hole_fill else chosen.copy()
    hull = _convex_hull(filled) if do_convex_hull else filled.copy()

    # Ellipse handling (robust for convex straight "bites")
    ellipse_used = False
    ellipse_reason = "off"
    ellipse_mask = np.zeros_like(hull)

    if ellipse_mode == "force":
        ellipse_mask, ellipse_used, ellipse_reason = _fit_ellipse_mask_from_contour(hull, scale=ellipse_scale)
        final = ellipse_mask
    elif ellipse_mode == "auto":
        need, why = _should_use_ellipse(hull, min_fill_ratio=ellipse_min_fill_ratio)
        ellipse_reason = why
        if need:
            # NEW: fit from real image boundary (robust to the 'chord' failure)
            ellipse_mask, ellipse_used, fit_why = _fit_ellipse_mask_from_ring_edges(
                g_corr, hull, scale=ellipse_scale, ring_width=25
            )
            if ellipse_used:
                ellipse_reason = f"{ellipse_reason} | {fit_why}"
                final = ellipse_mask
            else:
                # fallback to your old contour-based ellipse
                ellipse_mask, ellipse_used, fit_why2 = _fit_ellipse_mask_from_contour(hull, scale=ellipse_scale)
                ellipse_reason = f"{ellipse_reason} | fallback:{fit_why2}"
                final = ellipse_mask if ellipse_used else hull
        else:
            final = hull

    else:  # "off"
        final = hull

    final = (final > 0).astype(np.uint8) * 255

    if not return_debug:
        return final

    dbg = FOVMaskDebug(
        green_or_gray=g,
        blurred=blurred,
        otsu=otsu,
        candidate_chosen=chosen,
        after_morph=after_morph,
        largest_cc=chosen,
        filled=filled,
        convex_hull=hull,
        ellipse_mask=ellipse_mask,
        final=final,
        chosen_inverted=chosen_inverted,
        scores=scores,
        ellipse_used=ellipse_used,
        ellipse_reason=ellipse_reason,
    )
    return final, dbg

%%writefile test_fov_mask.py
import numpy as np
import cv2 as cv

from fov_mask import compute_fov_mask


def _iou(a: np.ndarray, b: np.ndarray) -> float:
    a = (a > 0)
    b = (b > 0)
    inter = np.logical_and(a, b).sum()
    union = np.logical_or(a, b).sum()
    return float(inter) / float(union + 1e-9)


def test_mask_is_binary_uint8():
    img = np.zeros((256, 256, 3), dtype=np.uint8)
    cv.circle(img, (128, 128), 90, (40, 180, 40), thickness=-1)  # green-ish disk
    mask = compute_fov_mask(img, do_hole_fill=True, do_convex_hull=True)

    assert mask.dtype == np.uint8
    vals = set(np.unique(mask).tolist())
    assert vals.issubset({0, 255})
    assert 0 in vals and 255 in vals


def test_circle_fov_high_iou_with_noise_and_holes():
    rng = np.random.default_rng(0)
    h, w = 512, 512
    img = np.zeros((h, w, 3), dtype=np.uint8)

    # Ideal circle FOV
    gt = np.zeros((h, w), dtype=np.uint8)
    cv.circle(gt, (w // 2, h // 2), 200, 255, thickness=-1)

    # Create fundus-like content inside the FOV
    base = np.zeros((h, w), dtype=np.uint8)
    base[gt > 0] = 150
    noise = rng.normal(0, 12, size=(h, w)).astype(np.float32)
    noisy = np.clip(base.astype(np.float32) + noise, 0, 255).astype(np.uint8)

    # Add holes inside the FOV (simulate gaps)
    holes = gt.copy()
    for _ in range(40):
        x = int(rng.integers(w // 2 - 150, w // 2 + 150))
        y = int(rng.integers(h // 2 - 150, h // 2 + 150))
        r = int(rng.integers(6, 18))
        cv.circle(holes, (x, y), r, 0, thickness=-1)

    noisy[holes == 0] = 0

    # Add random bright specks outside FOV
    for _ in range(300):
        x = int(rng.integers(0, w))
        y = int(rng.integers(0, h))
        if gt[y, x] == 0:
            noisy[y, x] = 255

    # Put into green channel (like real fundus)
    img[:, :, 1] = noisy

    mask = compute_fov_mask(
        img,
        blur_kind="median",
        blur_ksize=7,
        close_ksize=25,
        open_ksize=9,
        do_hole_fill=True,
        do_convex_hull=True,
    )

    score = _iou(mask, gt)
    assert score > 0.95, f"IoU too low: {score}"


def test_ellipse_fov_detected():
    rng = np.random.default_rng(1)
    h, w = 480, 640
    img = np.zeros((h, w, 3), dtype=np.uint8)

    gt = np.zeros((h, w), dtype=np.uint8)
    cv.ellipse(gt, (w // 2, h // 2), (240, 170), 0, 0, 360, 255, thickness=-1)

    base = np.zeros((h, w), dtype=np.uint8)
    base[gt > 0] = 140
    noise = rng.normal(0, 10, size=(h, w)).astype(np.float32)
    g = np.clip(base.astype(np.float32) + noise, 0, 255).astype(np.uint8)

    img[:, :, 1] = g

    mask = compute_fov_mask(
        img,
        blur_kind="gaussian",
        blur_ksize=7,
        close_ksize=31,
        open_ksize=11,
        do_hole_fill=True,
        do_convex_hull=True,
    )

    score = _iou(mask, gt)
    assert score > 0.93, f"IoU too low on ellipse: {score}"


def test_works_on_grayscale_input():
    h, w = 300, 300
    gray = np.zeros((h, w), dtype=np.uint8)
    cv.circle(gray, (150, 150), 110, 160, thickness=-1)

    mask = compute_fov_mask(gray, do_hole_fill=True, do_convex_hull=True)
    assert mask.shape == gray.shape
    assert mask.dtype == np.uint8
    assert set(np.unique(mask).tolist()).issubset({0, 255})




    !pip install opencv-python numpy pytest matplotlib


import os
from pathlib import Path
import cv2 as cv

img_path = Path("images/input/4.png")

print("cwd =", os.getcwd())
print("relative exists? =", img_path.exists())
print("absolute path =", img_path.resolve())
print("absolute exists? =", img_path.resolve().exists())

# OpenCV check
abs_path = str(img_path.resolve())
print("cv.haveImageReader =", cv.haveImageReader(abs_path))
img = cv.imread(abs_path, cv.IMREAD_UNCHANGED)
print("cv.imread is None? =", img is None)





from pathlib import Path
import os

def find_project_root(start: Path | None = None) -> Path:
    p = (start or Path.cwd()).resolve()
    for _ in range(25):
        if (p / "images" / "input").exists():
            return p
        if p.parent == p:
            break
        p = p.parent
    raise FileNotFoundError("Couldn't find a folder containing images/input")

ROOT = find_project_root()
print("cwd =", os.getcwd())
print("ROOT =", ROOT)



import cv2 as cv

img_path = ROOT / "images" / "input" / "4.png"
img = cv.imread(str(img_path), cv.IMREAD_UNCHANGED)
print("img is None?", img is None)




import cv2 as cv
from matplotlib import pyplot as plt
from pathlib import Path
import os

from fov_mask import compute_fov_mask

def find_project_root(start: Path | None = None) -> Path:
    p = (start or Path.cwd()).resolve()
    for _ in range(25):
        if (p / "images" / "input").exists():
            return p
        if p.parent == p:
            break
        p = p.parent
    raise FileNotFoundError("Couldn't find a folder containing images/input")

ROOT = find_project_root()  # <- keep this, DO NOT use .parent
print("cwd =", Path.cwd().resolve())
print("ROOT =", ROOT)

img_path = ROOT / "images" / "input" / "14.png"
print("img_path =", img_path)
print("exists? =", img_path.exists())

img = cv.imread(str(img_path), cv.IMREAD_UNCHANGED)
if img is None:
    raise FileNotFoundError(f"OpenCV could not read: {img_path}")

mask, dbg = compute_fov_mask(
    img,
    close_ksize=21,
    open_ksize=11,
    do_convex_hull=True,
    ellipse_mode="auto",
    ellipse_scale=1.01,
    return_debug=True
)

plt.figure(figsize=(18,4))
plt.subplot(1,5,1); plt.title("Green/Gray");  plt.imshow(dbg.green_or_gray, cmap="gray"); plt.axis("off")
plt.subplot(1,5,2); plt.title("Otsu");        plt.imshow(dbg.otsu, cmap="gray");          plt.axis("off")
plt.subplot(1,5,3); plt.title("Largest CC");  plt.imshow(dbg.largest_cc, cmap="gray");    plt.axis("off")
plt.subplot(1,5,4); plt.title("Convex hull"); plt.imshow(dbg.convex_hull, cmap="gray");   plt.axis("off")
plt.subplot(1,5,5); plt.title("Final");       plt.imshow(mask, cmap="gray");              plt.axis("off")
plt.show()

print("Chosen inverted:", dbg.chosen_inverted)
print("Scores:", dbg.scores)
print("Ellipse used:", dbg.ellipse_used)
print("Ellipse reason:", dbg.ellipse_reason)














%%writefile vessel_pipeline_a.py
# Pipeline A: Illumination correction -> vessel enhancement -> (GrabCut-style) graph cut refinement
# No deep learning / no supervised learning.

from __future__ import annotations

from dataclasses import dataclass
from typing import Any, Dict, Optional, Tuple

import numpy as np
import cv2 as cv

from pathlib import Path


try:
    # If your project already has a robust FOV detector, we will reuse it.
    from fov_mask import compute_fov_mask  # type: ignore
except Exception:
    compute_fov_mask = None  # fallback will be used

def _load_img_if_path(img_or_path):
    """
    Accept either:
      - np.ndarray image
      - str / Path path to an image on disk
    Returns np.ndarray (uint8).
    """
    if isinstance(img_or_path, (str, Path)):
        p = Path(img_or_path)
        im = cv.imread(str(p), cv.IMREAD_UNCHANGED)
        if im is None:
            raise FileNotFoundError(f"Could not read image at: {p}")
        return im
    return img_or_path

@dataclass
class PipelineAParams:
    # --- safety / early exits ---
    blank_std_thresh: float = 1.0          # if std(gray) < this AND max(gray) small -> blank
    blank_max_thresh: int = 2
    min_vessel_score: float = 0.03         # if vesselness max < this -> return empty

    # --- illumination correction / contrast ---
    bg_sigma: float = 25.0                 # background estimation for illumination correction
    clahe_clip: float = 2.0
    clahe_tile: int = 8

    # --- vessel enhancement (multi-scale black-hat) ---
    blackhat_ksizes: Tuple[int, int, int] = (9, 15, 23)  # odd sizes
    smooth_sigma: float = 1.2

    # --- GrabCut (GraphCut) refinement ---
    grabcut_iters: int = 3
    pr_fg_quantile: float = 0.80           # probable FG threshold quantile
    fg_quantile: float = 0.93              # sure FG threshold quantile
    bg_quantile: float = 0.55              # sure BG threshold quantile
    min_fg_pixels: int = 40                # ensure some FG seeds exist
    min_pr_fg_pixels: int = 200            # ensure some probable FG exists

    # --- postprocessing ---
    min_component_area: int = 20
    open_ksize: int = 3                    # remove specks
    close_ksize: int = 3                   # connect tiny gaps

    # --- fallback FOV ---
    fov_nonzero_thresh: int = 1            # for fallback FOV from green channel
    fov_close_ksize: int = 21


def _dbg(verbose: bool, msg: str) -> None:
    if verbose:
        print(msg)


def _to_green(img: np.ndarray) -> np.ndarray:
    if img.ndim == 2:
        return img
    if img.ndim == 3 and img.shape[2] >= 3:
        # works for both RGB and BGR because G is channel 1 in both
        return img[:, :, 1]
    raise ValueError(f"Unsupported image shape: {img.shape}")


def _fallback_fov_mask(g: np.ndarray, params: PipelineAParams) -> np.ndarray:
    # basic: anything non-black, then close to get one blob, then take largest CC
    thr = (g > int(params.fov_nonzero_thresh)).astype(np.uint8) * 255
    if thr.sum() == 0:
        return np.zeros_like(g, dtype=np.uint8)

    k = int(params.fov_close_ksize)
    if k % 2 == 0:
        k += 1
    kernel = cv.getStructuringElement(cv.MORPH_ELLIPSE, (k, k))
    closed = cv.morphologyEx(thr, cv.MORPH_CLOSE, kernel)

    n, labels, stats, _ = cv.connectedComponentsWithStats((closed > 0).astype(np.uint8), connectivity=8)
    if n <= 1:
        return (closed > 0).astype(np.uint8) * 255

    # largest non-background component
    areas = stats[1:, cv.CC_STAT_AREA]
    idx = 1 + int(np.argmax(areas))
    fov = (labels == idx).astype(np.uint8) * 255
    return fov


def _compute_fov(g: np.ndarray, params: PipelineAParams, verbose: bool, debug: Dict[str, Any]) -> np.ndarray:
    if compute_fov_mask is not None:
        try:
            fov = compute_fov_mask(g)  # project function
            fov = (fov > 0).astype(np.uint8) * 255
            debug["fov_source"] = "compute_fov_mask"
            return fov
        except Exception as e:
            _dbg(verbose, f"[PipelineA] compute_fov_mask failed -> fallback. Reason: {e!r}")
            debug["fov_source"] = "fallback_due_to_exception"

    fov = _fallback_fov_mask(g, params)
    debug["fov_source"] = "fallback"
    return fov


def _illumination_correct_and_clahe(g: np.ndarray, params: PipelineAParams) -> np.ndarray:
    g_f = g.astype(np.float32)
    bg = cv.GaussianBlur(g_f, (0, 0), sigmaX=float(params.bg_sigma), sigmaY=float(params.bg_sigma))
    corr = g_f - bg
    # normalize to 8-bit
    corr_u8 = cv.normalize(corr, None, 0, 255, cv.NORM_MINMAX).astype(np.uint8)

    clahe = cv.createCLAHE(clipLimit=float(params.clahe_clip),
                           tileGridSize=(int(params.clahe_tile), int(params.clahe_tile)))
    eq = clahe.apply(corr_u8)
    return eq


def _vessel_enhance(eq_u8: np.ndarray, fov_u8: np.ndarray, params: PipelineAParams) -> np.ndarray:
    # Multi-scale black-hat to highlight dark thin structures
    scores = []
    for k in params.blackhat_ksizes:
        k = int(k)
        if k < 3:
            k = 3
        if k % 2 == 0:
            k += 1
        kernel = cv.getStructuringElement(cv.MORPH_ELLIPSE, (k, k))
        bh = cv.morphologyEx(eq_u8, cv.MORPH_BLACKHAT, kernel)
        scores.append(bh.astype(np.float32))

    v = np.maximum.reduce(scores) if len(scores) > 1 else scores[0]
    v = v / 255.0

    # smooth a bit
    if float(params.smooth_sigma) > 0:
        v = cv.GaussianBlur(v, (0, 0), sigmaX=float(params.smooth_sigma), sigmaY=float(params.smooth_sigma))

    # zero outside FOV
    v[fov_u8 == 0] = 0.0

    # normalize inside FOV for stability
    inside = v[fov_u8 > 0]
    if inside.size > 0:
        vmin = float(np.min(inside))
        vmax = float(np.max(inside))
        if vmax > vmin + 1e-6:
            v = (v - vmin) / (vmax - vmin)
            v[fov_u8 == 0] = 0.0
    return v


def _ensure_min_seeds(score: np.ndarray, fov: np.ndarray, mask: np.ndarray, label: int, min_pixels: int) -> None:
    # Add top-K pixels as seeds if too few exist.
    cur = int((mask == label).sum())
    if cur >= int(min_pixels):
        return
    inside = np.where(fov > 0)
    if inside[0].size == 0:
        return
    vals = score[inside]
    if vals.size == 0:
        return
    k = int(min_pixels - cur)
    k = min(k, vals.size)
    if k <= 0:
        return
    # indices of top-k by score
    order = np.argpartition(vals, -k)[-k:]
    ys = inside[0][order]
    xs = inside[1][order]
    mask[ys, xs] = label


def _postprocess(bin_u8: np.ndarray, params: PipelineAParams) -> np.ndarray:
    m = (bin_u8 > 0).astype(np.uint8) * 255

    # opening/closing
    ok = int(params.open_ksize)
    ck = int(params.close_ksize)
    if ok >= 3:
        if ok % 2 == 0:
            ok += 1
        k = cv.getStructuringElement(cv.MORPH_ELLIPSE, (ok, ok))
        m = cv.morphologyEx(m, cv.MORPH_OPEN, k)
    if ck >= 3:
        if ck % 2 == 0:
            ck += 1
        k = cv.getStructuringElement(cv.MORPH_ELLIPSE, (ck, ck))
        m = cv.morphologyEx(m, cv.MORPH_CLOSE, k)

    # remove tiny components
    n, labels, stats, _ = cv.connectedComponentsWithStats((m > 0).astype(np.uint8), connectivity=8)
    if n <= 1:
        return m

    out = np.zeros_like(m)
    for i in range(1, n):
        area = int(stats[i, cv.CC_STAT_AREA])
        if area >= int(params.min_component_area):
            out[labels == i] = 255
    return out


def vessel_segmentation(
    img: np.ndarray,
    verbose: bool = False,
    params: Optional[PipelineAParams] = None,
    return_debug: bool = False,
):
    """
    Returns a binary vessel mask (uint8, values {0,255}).

    Key fixes for your failing tests:
    - Hard blank-image early exit -> ALWAYS returns all zeros.
    - Vesselness sanity check (max score too small) -> returns all zeros.
    - Robust GrabCut seeding + fallback seed enforcement so synthetic lines are detected.
    """
    if params is None:
        params = PipelineAParams()

    debug: Dict[str, Any] = {}

    img = _load_img_if_path(img)

    g = _to_green(img)
    g_u8 = g.astype(np.uint8)

    # ---- (1) blank / near-blank early exit ----
    g_std = float(np.std(g_u8))
    g_max = int(np.max(g_u8)) if g_u8.size else 0
    debug["g_std"] = g_std
    debug["g_max"] = g_max
    _dbg(verbose, f"[PipelineA] green std={g_std:.3f}, max={g_max}")

    if (g_std < float(params.blank_std_thresh)) and (g_max <= int(params.blank_max_thresh)):
        out = np.zeros(g_u8.shape, dtype=np.uint8)
        debug["early_exit"] = "blank_image"
        if return_debug:
            return out, debug
        return out

    # ---- (2) FOV ----
    fov_u8 = _compute_fov(g_u8, params, verbose, debug)
    fov_area = int((fov_u8 > 0).sum())
    debug["fov_area"] = fov_area
    _dbg(verbose, f"[PipelineA] FOV source={debug.get('fov_source')} area={fov_area}")

    if fov_area == 0:
        out = np.zeros(g_u8.shape, dtype=np.uint8)
        debug["early_exit"] = "empty_fov"
        if return_debug:
            return out, debug
        return out

    # ---- (3) illumination correction + CLAHE ----
    eq = _illumination_correct_and_clahe(g_u8, params)

    # ---- (4) vessel enhancement ----
    score = _vessel_enhance(eq, fov_u8, params)
    smax = float(np.max(score)) if score.size else 0.0
    debug["vessel_score_max"] = smax
    _dbg(verbose, f"[PipelineA] vessel_score max={smax:.4f}")

    # If no vessel signal at all, return empty (fixes blank-like images + avoids all-foreground grabcut)
    if smax < float(params.min_vessel_score):
        out = np.zeros(g_u8.shape, dtype=np.uint8)
        debug["early_exit"] = "no_vessel_signal"
        if return_debug:
            return out, debug
        return out

    # ---- (5) build GrabCut mask (GraphCut) ----
    inside = score[fov_u8 > 0]
    pr_thr = float(np.quantile(inside, float(params.pr_fg_quantile)))
    fg_thr = float(np.quantile(inside, float(params.fg_quantile)))
    bg_thr = float(np.quantile(inside, float(params.bg_quantile)))
    debug.update({"pr_thr": pr_thr, "fg_thr": fg_thr, "bg_thr": bg_thr})
    _dbg(verbose, f"[PipelineA] thresholds: bg={bg_thr:.4f}, pr_fg={pr_thr:.4f}, fg={fg_thr:.4f}")

    # init: background everywhere, probable background inside FOV
    gc = np.full(g_u8.shape, cv.GC_BGD, dtype=np.uint8)
    gc[fov_u8 > 0] = cv.GC_PR_BGD

    # probable FG / sure FG / sure BG
    prob_fg = (score >= pr_thr) & (fov_u8 > 0)
    sure_fg = (score >= fg_thr) & (fov_u8 > 0)
    sure_bg = (score <= bg_thr) & (fov_u8 > 0)

    gc[prob_fg] = cv.GC_PR_FGD
    gc[sure_fg] = cv.GC_FGD
    gc[sure_bg] = cv.GC_BGD
    gc[fov_u8 == 0] = cv.GC_BGD

    # enforce a minimum number of seeds so synthetic doesn’t end up with zero FG seeds
    _ensure_min_seeds(score, fov_u8, gc, cv.GC_FGD, int(params.min_fg_pixels))
    _ensure_min_seeds(score, fov_u8, gc, cv.GC_PR_FGD, int(params.min_pr_fg_pixels))

    debug["n_sure_fg"] = int((gc == cv.GC_FGD).sum())
    debug["n_pr_fg"] = int((gc == cv.GC_PR_FGD).sum())
    debug["n_sure_bg"] = int((gc == cv.GC_BGD).sum())
    _dbg(verbose, f"[PipelineA] seeds: sure_fg={debug['n_sure_fg']}, pr_fg={debug['n_pr_fg']}")

    # ---- (6) GrabCut ----
    bgdModel = np.zeros((1, 65), np.float64)
    fgdModel = np.zeros((1, 65), np.float64)

    try:
        cv.grabCut(
            img if img.ndim == 3 else cv.cvtColor(g_u8, cv.COLOR_GRAY2BGR),
            gc,
            None,
            bgdModel,
            fgdModel,
            int(params.grabcut_iters),
            mode=cv.GC_INIT_WITH_MASK,
        )
        debug["grabcut_ok"] = True
    except Exception as e:
        # If grabcut fails, we fallback to thresholding score (still should pass synthetic test).
        debug["grabcut_ok"] = False
        debug["grabcut_error"] = repr(e)
        _dbg(verbose, f"[PipelineA] grabCut failed -> fallback threshold. Reason: {e!r}")

        thr = float(np.quantile(inside, 0.90))
        out = ((score >= thr) & (fov_u8 > 0)).astype(np.uint8) * 255
        out = _postprocess(out, params)
        if return_debug:
            return out, debug
        return out

    # Extract FG + Probable FG, then clamp to FOV
    out = np.where((gc == cv.GC_FGD) | (gc == cv.GC_PR_FGD), 255, 0).astype(np.uint8)
    out[fov_u8 == 0] = 0

    # ---- (7) postprocess ----
    out = _postprocess(out, params)

    debug["out_nz"] = int((out > 0).sum())
    _dbg(verbose, f"[PipelineA] output nz={debug['out_nz']}")

    if return_debug:
        return out, debug
    return out














%%writefile test_pipeline_a.py
import numpy as np
import cv2 as cv

from fov_mask import compute_fov_mask
from vessel_pipeline_a import vessel_segmentation, PipelineAParams


def _make_synthetic_fundus(h=256, w=256, *, seed=0):
    """
    Create a synthetic 'fundus-like' image:
    - circular FOV
    - background illumination
    - a few dark vessel-like lines
    Returns (bgr_img, fov_gt_u8, vessel_gt_u8)
    """
    rng = np.random.default_rng(seed)

    # FOV ground truth
    fov = np.zeros((h, w), dtype=np.uint8)
    cv.circle(fov, (w // 2, h // 2), int(min(h, w) * 0.43), 255, -1)

    # Base green channel: inside FOV medium intensity, outside black
    g = np.zeros((h, w), dtype=np.uint8)
    g[fov > 0] = 160

    # Add smooth illumination gradient inside FOV
    yy, xx = np.mgrid[0:h, 0:w]
    grad = (20.0 * (xx.astype(np.float32) / max(1, w - 1))).astype(np.float32)
    g = np.clip(g.astype(np.float32) + grad, 0, 255).astype(np.uint8)
    g[fov == 0] = 0

    # Draw vessel-like dark lines (GT)
    vessel_gt = np.zeros((h, w), dtype=np.uint8)
    lines = [
        ((w//2 - 70, h//2 - 10), (w//2 + 70, h//2 + 10)),
        ((w//2 - 30, h//2 - 80), (w//2 + 10, h//2 + 80)),
        ((w//2 - 80, h//2 + 40), (w//2 + 60, h//2 + 20)),
    ]
    for (x0, y0), (x1, y1) in lines:
        cv.line(vessel_gt, (x0, y0), (x1, y1), 255, thickness=2)

    vessel_gt[fov == 0] = 0

    # Apply vessels to image (darken)
    g2 = g.copy()
    g2[vessel_gt > 0] = 60

    # Add mild noise
    noise = rng.normal(0, 6, size=(h, w)).astype(np.float32)
    g2 = np.clip(g2.astype(np.float32) + noise, 0, 255).astype(np.uint8)
    g2[fov == 0] = 0

    # Build BGR
    bgr = np.zeros((h, w, 3), dtype=np.uint8)
    bgr[:, :, 1] = g2
    return bgr, fov, vessel_gt


def test_fov_mask_binary_and_nonempty():
    img, fov_gt, _ = _make_synthetic_fundus()
    mask = compute_fov_mask(img, close_ksize=21, open_ksize=11, do_convex_hull=True)

    assert mask.dtype == np.uint8
    vals = set(np.unique(mask).tolist())
    assert vals.issubset({0, 255})
    assert (mask > 0).sum() > 1000


def test_pipeline_a_output_binary_shape_and_dtype():
    img, fov_gt, _ = _make_synthetic_fundus()
    out = vessel_segmentation(img, verbose=False)

    assert out.shape == (img.shape[0], img.shape[1])
    assert out.dtype == np.uint8
    vals = set(np.unique(out).tolist())
    assert vals.issubset({0, 255})


def test_pipeline_a_respects_fov_outside_is_zero():
    img, fov_gt, _ = _make_synthetic_fundus()
    out = vessel_segmentation(img, verbose=False)

    # Outside GT FOV should be zero (strict)
    assert int((out[fov_gt == 0] > 0).sum()) == 0


def test_pipeline_a_detects_some_vessels_on_easy_synthetic():
    img, fov_gt, vessel_gt = _make_synthetic_fundus()

    # Use slightly stronger grabcut iterations for stability in synthetic
    params = PipelineAParams(grabcut_iters=5)

    out = vessel_segmentation(img, verbose=False, params=params)

    # Should detect something inside FOV
    nz = int((out > 0).sum())
    assert nz > 50, f"Too few detected vessel pixels: {nz}"

    # Should not explode to fill most FOV
    fov_area = int((fov_gt > 0).sum())
    assert nz < int(0.60 * fov_area), f"Detected vessel area too large: {nz} vs fov_area={fov_area}"


def test_pipeline_a_blank_image_returns_empty_or_near_empty():
    h, w = 240, 320
    img = np.zeros((h, w, 3), dtype=np.uint8)
    out = vessel_segmentation(img, verbose=False)

    # On blank, we expect no vessels
    assert int((out > 0).sum()) == 0










import os
from pathlib import Path
import cv2 as cv
from matplotlib import pyplot as plt

from vessel_pipeline_a import vessel_segmentation  # <- Pipeline A

def find_project_root(start: Path | None = None) -> Path:
    p = (start or Path.cwd()).resolve()
    for _ in range(25):
        if (p / "images" / "input").exists():
            return p
        if p.parent == p:
            break
        p = p.parent
    raise FileNotFoundError("Couldn't find a folder containing images/input")

ROOT = find_project_root()
img_path = ROOT / "images" / "input"
gt_path = ROOT / "images" / "gt"

print("ROOT:", ROOT)
print("Input dir:", img_path, "| exists:", img_path.exists())
print("GT dir:", gt_path, "| exists:", gt_path.exists())

def single_IoU(img_name: str) -> float:
    input_img = img_path / img_name
    obtained = vessel_segmentation(str(input_img), verbose=False)

    target_img = gt_path / img_name
    solution = cv.imread(str(target_img), cv.IMREAD_GRAYSCALE)

    obtained = (obtained > 0).astype("uint8") * 255
    solution = (solution > 0).astype("uint8") * 255

    print(f"[DBG] {img_name} | obtained shape={obtained.shape} unique={sorted(set(obtained.ravel().tolist()))[:5]}")
    print(f"[DBG] {img_name} | solution shape={solution.shape} unique={sorted(set(solution.ravel().tolist()))[:5]}")

    plt.imshow(obtained, cmap="gray")
    plt.title(f"Obtained: {img_name}")
    plt.axis("off")
    plt.show()

    intersectionAB = cv.countNonZero(cv.bitwise_and(obtained, solution))
    unionAB = cv.countNonZero(cv.bitwise_or(obtained, solution))
    score = float(intersectionAB) / float(unionAB + 1e-9)

    print(f"Image {img_name} - IoU={score:.6f}")
    return score

meanIoU = 0.0
imgs = sorted([p.name for p in img_path.iterdir() if p.suffix.lower() == ".png"])
print("Images:", imgs)

for img in imgs:
    meanIoU += single_IoU(img)

meanIoU /= max(1, len(imgs))
print("------------------------------------")
print(f"Mean IoU={meanIoU:.6f}")



# === Grid search (hand-picked combos) for Pipeline A ===
# Shows overlays + prints params + per-image IoU + summary ranking.
#
# RED=Prediction, GREEN=Ground Truth, YELLOW=Overlap
#
# Tip: if this is too slow while tuning, set MAX_IMAGES=6 (or similar).

import time
import numpy as np
import cv2 as cv
import pandas as pd
from pathlib import Path
from dataclasses import asdict
from matplotlib import pyplot as plt
from IPython.display import display

from vessel_pipeline_a import vessel_segmentation, PipelineAParams


# -----------------------------
# Helpers (same style as Pipeline C cell)
# -----------------------------
def find_project_root(start: Path | None = None) -> Path:
    p = (start or Path.cwd()).resolve()
    for _ in range(30):
        if (p / "images" / "input").exists() and (p / "images" / "gt").exists():
            return p
        if p.parent == p:
            break
        p = p.parent
    raise FileNotFoundError("Couldn't find a folder containing images/input and images/gt")

def bin255(x: np.ndarray) -> np.ndarray:
    return (x > 0).astype(np.uint8) * 255

def iou(pred255: np.ndarray, gt255: np.ndarray) -> float:
    p = (pred255 > 0)
    g = (gt255 > 0)
    inter = np.logical_and(p, g).sum()
    union = np.logical_or(p, g).sum()
    return float(inter) / float(union + 1e-9)

def overlay_rg(pred255: np.ndarray, gt255: np.ndarray) -> np.ndarray:
    # RED=pred, GREEN=gt, YELLOW=overlap
    p = (pred255 > 0).astype(np.uint8) * 255
    g = (gt255 > 0).astype(np.uint8) * 255
    out = np.zeros((pred255.shape[0], pred255.shape[1], 3), dtype=np.uint8)
    out[..., 0] = p  # R
    out[..., 1] = g  # G
    out[..., 2] = 0  # B
    return out

def show_grid(images, titles, ncols=5, figsize=(18, 12), suptitle=None):
    n = len(images)
    ncols = int(ncols)
    nrows = int(np.ceil(n / ncols))
    plt.figure(figsize=figsize)
    for i in range(n):
        plt.subplot(nrows, ncols, i + 1)
        img = images[i]
        if img.ndim == 2:
            plt.imshow(img, cmap="gray")
        else:
            plt.imshow(img)
        plt.title(titles[i], fontsize=9)
        plt.axis("off")
    if suptitle:
        plt.suptitle(suptitle, fontsize=14)
    plt.tight_layout()
    plt.show()


# -----------------------------
# Dataset paths (project-local)  <-- EXACTLY as you requested
# -----------------------------
ROOT = find_project_root()
img_path = ROOT / "images" / "input"
gt_path  = ROOT / "images" / "gt"

imgs = sorted([p.name for p in img_path.iterdir() if p.suffix.lower() == ".png"])
if not imgs:
    raise FileNotFoundError(f"No .png images found in: {img_path}")

print("ROOT:", ROOT)
print("Num images:", len(imgs))
print("Images:", imgs)


# -----------------------------
# Hand-picked parameter combinations (designed to move IoU)
# -----------------------------
# Rationale (high-level):
# - Sensitivity knobs: blackhat_ksizes smaller, smooth_sigma smaller, pr/fg quantiles lower, smaller min_component_area
# - Precision knobs: blackhat_ksizes larger, smooth_sigma larger, pr/fg quantiles higher, larger open_ksize/min_component_area
# - Retinex/contrast knobs: bg_sigma, clahe_clip/tile
# - GraphCut stability knobs: grabcut_iters, seed minima (min_fg_pixels/min_pr_fg_pixels)
COMBOS = [
    dict(
        name="baseline_defaults",
        overrides=dict(
            # no overrides (kept explicit for clarity)
        ),
    ),
    dict(
        name="sensitive_thin_vessels",
        overrides=dict(
            blackhat_ksizes=(7, 11, 15),
            smooth_sigma=0.8,
            pr_fg_quantile=0.72,
            fg_quantile=0.90,
            bg_quantile=0.58,
            grabcut_iters=5,
            min_component_area=12,
            open_ksize=3,
            close_ksize=5,
        ),
    ),
    dict(
        name="balanced_plus_connectivity",
        overrides=dict(
            blackhat_ksizes=(9, 15, 23),
            smooth_sigma=1.0,
            pr_fg_quantile=0.78,
            fg_quantile=0.92,
            bg_quantile=0.55,
            grabcut_iters=6,
            min_component_area=18,
            open_ksize=3,
            close_ksize=7,
        ),
    ),
    dict(
        name="precision_reduce_fp",
        overrides=dict(
            blackhat_ksizes=(11, 19, 27),
            smooth_sigma=1.4,
            pr_fg_quantile=0.84,
            fg_quantile=0.96,
            bg_quantile=0.50,
            grabcut_iters=4,
            min_component_area=40,
            open_ksize=5,
            close_ksize=3,
            min_vessel_score=0.02,   # keep permissive (avoid accidental empty outputs)
        ),
    ),
    dict(
        name="strong_clahe_low_contrast_rescue",
        overrides=dict(
            bg_sigma=30.0,
            clahe_clip=3.5,
            clahe_tile=8,
            blackhat_ksizes=(9, 15, 23),
            smooth_sigma=1.0,
            pr_fg_quantile=0.76,
            fg_quantile=0.92,
            bg_quantile=0.56,
            grabcut_iters=5,
            min_component_area=18,
            open_ksize=3,
            close_ksize=5,
        ),
    ),
    dict(
        name="retinex_more_local_detail",
        overrides=dict(
            bg_sigma=18.0,           # less aggressive illumination field -> preserves more local variation
            clahe_clip=2.2,
            clahe_tile=8,
            blackhat_ksizes=(7, 13, 19),
            smooth_sigma=0.7,
            pr_fg_quantile=0.74,
            fg_quantile=0.91,
            bg_quantile=0.58,
            grabcut_iters=5,
            min_component_area=14,
            open_ksize=3,
            close_ksize=5,
        ),
    ),
    dict(
        name="seed_heavy_grabcut_stability",
        overrides=dict(
            blackhat_ksizes=(9, 15, 23),
            smooth_sigma=1.0,
            pr_fg_quantile=0.80,
            fg_quantile=0.93,
            bg_quantile=0.55,
            grabcut_iters=7,
            min_fg_pixels=120,
            min_pr_fg_pixels=450,
            min_component_area=20,
            open_ksize=3,
            close_ksize=5,
        ),
    ),
    dict(
        name="minimal_smoothing_thin_edges",
        overrides=dict(
            blackhat_ksizes=(7, 11, 17),
            smooth_sigma=0.0,        # keep high-frequency thin details
            pr_fg_quantile=0.74,
            fg_quantile=0.90,
            bg_quantile=0.60,
            grabcut_iters=5,
            min_component_area=10,
            open_ksize=3,
            close_ksize=5,
        ),
    ),
]


# -----------------------------
# Run all combos
# -----------------------------
ALL_RESULTS = []

# If you want to run faster while tuning, set e.g. MAX_IMAGES=6
MAX_IMAGES = None  # None => use all images
eval_imgs = imgs if MAX_IMAGES is None else imgs[:MAX_IMAGES]

for ci, combo in enumerate(COMBOS, start=1):
    name = combo["name"]
    overrides = combo["overrides"]

    # Build PipelineAParams
    params = PipelineAParams(**overrides)

    print("\n" + "="*90)
    print(f"[{ci}/{len(COMBOS)}] COMBO: {name}")
    print("Overrides:")
    if overrides:
        for k in sorted(overrides.keys()):
            print(f"  - {k}: {overrides[k]}")
    else:
        print("  (none; using PipelineAParams defaults)")

    per_image = []
    overlays = []
    titles = []

    t0 = time.perf_counter()

    for img_name in eval_imgs:
        in_path = img_path / img_name
        gt_p    = gt_path / img_name

        gt = cv.imread(str(gt_p), cv.IMREAD_GRAYSCALE)
        if gt is None:
            print(f"[WARN] Could not read GT: {gt_p}")
            continue

        pred = vessel_segmentation(str(in_path), verbose=False, params=params, return_debug=False)

        pred = bin255(pred)
        gt   = bin255(gt)

        sc = iou(pred, gt)
        per_image.append(dict(image=img_name, iou=sc))

        overlays.append(overlay_rg(pred, gt))
        titles.append(f"{img_name}\nIoU={sc:.4f}")

    t1 = time.perf_counter()
    df = pd.DataFrame(per_image).sort_values("image").reset_index(drop=True)

    if len(df) == 0:
        print("[ERROR] No images were evaluated for this combo.")
        continue

    mean_iou = float(df["iou"].mean())
    med_iou  = float(df["iou"].median())
    std_iou  = float(df["iou"].std(ddof=0))
    min_iou  = float(df["iou"].min())
    max_iou  = float(df["iou"].max())
    sec_per_img = (t1 - t0) / max(1, len(df))

    print("\nSummary:")
    print(f"  mean IoU  = {mean_iou:.6f}")
    print(f"  median    = {med_iou:.6f}")
    print(f"  std       = {std_iou:.6f}")
    print(f"  min / max = {min_iou:.6f} / {max_iou:.6f}")
    print(f"  time/img  = {sec_per_img:.3f} s")

    # Per-image IoU table
    display(df)

    # Overlays grid
    show_grid(
        overlays,
        titles,
        ncols=5,
        figsize=(18, 12),
        suptitle=f"{name} | mean IoU={mean_iou:.4f} | RED=Pred, GREEN=GT, YELLOW=Overlap"
    )

    # Representative debug (median-IoU image)
    rep_row = df.iloc[int(len(df) // 2)]
    rep_name = rep_row["image"]

    seg_rep, dbg = vessel_segmentation(str(img_path / rep_name), return_debug=True, verbose=False, params=params)
    print(f"[Representative debug] image={rep_name} | IoU={float(rep_row['iou']):.4f}")

    # Print key debug fields (compact + useful)
    key_order = [
        "early_exit",
        "g_std", "g_max",
        "fov_source", "fov_area",
        "vessel_score_max",
        "bg_thr", "pr_thr", "fg_thr",
        "n_sure_fg", "n_pr_fg", "n_sure_bg",
        "grabcut_ok", "grabcut_error",
        "out_nz",
    ]
    for k in key_order:
        if k in dbg:
            print(f"  dbg[{k!s}] = {dbg[k]}")

    # Save ranking row
    ALL_RESULTS.append(dict(
        combo=name,
        mean_iou=mean_iou,
        median_iou=med_iou,
        std_iou=std_iou,
        min_iou=min_iou,
        max_iou=max_iou,
        time_per_img_s=sec_per_img,
    ))

# Final ranking
rank = pd.DataFrame(ALL_RESULTS).sort_values(["mean_iou", "median_iou"], ascending=False).reset_index(drop=True)
print("\n" + "#"*90)
print("RANKING (sorted by mean IoU desc):")
display(rank)
