%%writefile fov_mask.py
from __future__ import annotations

from dataclasses import dataclass
from typing import Dict, Optional, Tuple, Union, Literal

import numpy as np
import cv2 as cv

Array = np.ndarray


@dataclass
class FOVMaskDebug:
    """Optional debug outputs to inspect intermediate steps."""
    green_or_gray: Array
    blurred: Array
    otsu: Array
    candidate_chosen: Array
    after_morph: Array
    largest_cc: Array
    filled: Array
    convex_hull: Array
    ellipse_mask: Array
    final: Array
    chosen_inverted: bool
    scores: Dict[str, float]
    ellipse_used: bool
    ellipse_reason: str


def _to_uint8(gray: Array) -> Array:
    if gray.dtype == np.uint8:
        return gray
    g = gray.astype(np.float32)
    g = g - g.min()
    denom = (g.max() - g.min()) if (g.max() - g.min()) > 1e-6 else 1.0
    return (255.0 * g / denom).clip(0, 255).astype(np.uint8)

def _flatfield_for_otsu(g: Array) -> Array:
    """
    Remove slow illumination gradients (vignetting) so global thresholding
    doesn't 'eat' the dark retinal rim.
    """
    h, w = g.shape[:2]
    sigma = 0.12 * float(min(h, w))  # large blur = illumination field
    bg = cv.GaussianBlur(g, (0, 0), sigmaX=sigma, sigmaY=sigma)

    # flat-field: g / bg
    corr = cv.divide(g, bg, scale=255.0)
    corr = cv.normalize(corr, None, 0, 255, cv.NORM_MINMAX)
    return corr.astype(np.uint8)


def _to_gray_or_green(img: Array) -> Array:
    """
    Convert input (BGR/RGB/GRAY) to a single-channel image.
    For fundus images, green channel usually gives best contrast.
    """
    if img is None:
        raise ValueError("Input image is None.")
    if img.ndim == 2:
        gray = img
    elif img.ndim == 3 and img.shape[2] >= 3:
        # OpenCV loads as BGR by default
        gray = img[:, :, 1]  # green channel
    else:
        raise ValueError(f"Unsupported image shape: {img.shape}")
    return _to_uint8(gray)


def _ensure_odd(k: int) -> int:
    k = int(k)
    if k < 1:
        k = 1
    if k % 2 == 0:
        k += 1
    return k


def _auto_ksizes(h: int, w: int) -> Tuple[int, int]:
    """
    Auto choose morphology kernel sizes based on image diagonal.
    Tuned to be "safe" for common fundus sizes (e.g., DRIVE 768x584).
    """
    diag = float(np.hypot(h, w))
    close_k = _ensure_odd(int(round(diag * 0.035)))  # ~33 for DRIVE
    open_k = _ensure_odd(int(round(diag * 0.012)))   # ~11 for DRIVE
    close_k = max(close_k, 25)
    open_k = max(open_k, 9)
    return close_k, open_k


def _morph_cleanup(mask: Array, close_ksize: int, open_ksize: int) -> Array:
    """Close gaps then open to remove specks."""
    close_ksize = _ensure_odd(close_ksize)
    open_ksize = _ensure_odd(open_ksize)

    close_k = cv.getStructuringElement(cv.MORPH_ELLIPSE, (close_ksize, close_ksize))
    open_k = cv.getStructuringElement(cv.MORPH_ELLIPSE, (open_ksize, open_ksize))

    m = cv.morphologyEx(mask, cv.MORPH_CLOSE, close_k)
    m = cv.morphologyEx(m, cv.MORPH_OPEN, open_k)
    return m


def _largest_connected_component(mask: Array) -> Array:
    """Return a binary mask (0/255) containing only the largest foreground CC."""
    m = (mask > 0).astype(np.uint8)
    num, labels, stats, _ = cv.connectedComponentsWithStats(m, connectivity=8)
    if num <= 1:
        return np.zeros_like(mask, dtype=np.uint8)

    areas = stats[1:, cv.CC_STAT_AREA]
    best_idx = 1 + int(np.argmax(areas))
    out = np.zeros_like(mask, dtype=np.uint8)
    out[labels == best_idx] = 255
    return out


def _fill_holes(mask: Array) -> Array:
    """
    Fill holes inside a binary object using flood-fill on the background.
    Input/Output are 0/255 uint8.
    More robust than using only (0,0) as seed.
    """
    m = (mask > 0).astype(np.uint8) * 255
    h, w = m.shape[:2]
    if h == 0 or w == 0:
        return m

    # find a background seed on the border
    border_coords = []
    border_coords += [(0, x) for x in range(w)]
    border_coords += [(h - 1, x) for x in range(w)]
    border_coords += [(y, 0) for y in range(h)]
    border_coords += [(y, w - 1) for y in range(h)]

    seed = None
    for (yy, xx) in border_coords:
        if m[yy, xx] == 0:
            seed = (xx, yy)  # floodFill uses (x,y)
            break
    if seed is None:
        # mask covers the whole border; nothing to flood-fill safely
        return m

    inv = cv.bitwise_not(m)
    ff = inv.copy()
    flood_mask = np.zeros((h + 2, w + 2), dtype=np.uint8)
    cv.floodFill(ff, flood_mask, seedPoint=seed, newVal=0)

    holes = (ff > 0).astype(np.uint8) * 255
    filled = cv.bitwise_or(m, holes)
    return filled


def _convex_hull(mask: Array) -> Array:
    """Return convex hull of the largest object as 0/255 mask."""
    m = (mask > 0).astype(np.uint8) * 255
    contours, _ = cv.findContours(m, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)
    if not contours:
        return np.zeros_like(m, dtype=np.uint8)

    cnt = max(contours, key=cv.contourArea)
    hull = cv.convexHull(cnt)
    out = np.zeros_like(m, dtype=np.uint8)
    cv.drawContours(out, [hull], -1, 255, thickness=cv.FILLED)
    return out


def _candidate_score(candidate_mask: Array) -> float:
    """
    Score a candidate FOV mask.
    Heuristics (good FOV):
      - large area but not the whole image
      - centered
      - low border contact
      - reasonably compact
    """
    m = (candidate_mask > 0).astype(np.uint8)
    h, w = m.shape[:2]
    area = float(m.sum())
    area_ratio = area / float(h * w)

    if area < 10:
        return -1e9

    border = np.concatenate([m[0, :], m[-1, :], m[:, 0], m[:, -1]])
    border_ratio = float(border.mean())

    ys, xs = np.where(m > 0)
    cy, cx = float(np.mean(ys)), float(np.mean(xs))
    center_dist = np.sqrt((cy - (h / 2.0)) ** 2 + (cx - (w / 2.0)) ** 2)
    center_dist_norm = center_dist / np.sqrt((h / 2.0) ** 2 + (w / 2.0) ** 2)

    circ = 0.0
    m255 = (m * 255).astype(np.uint8)
    contours, _ = cv.findContours(m255, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)
    if contours:
        cnt = max(contours, key=cv.contourArea)
        A = float(cv.contourArea(cnt))
        P = float(cv.arcLength(cnt, True))
        circ = (4.0 * np.pi * A) / (P * P + 1e-6)

    area_penalty = 0.6 if (area_ratio < 0.10 or area_ratio > 0.98) else 0.0

    score = (
        + 1.5 * area_ratio
        - 2.0 * border_ratio
        - 0.8 * center_dist_norm
        + 0.4 * circ
        - area_penalty
    )
    return float(score)


def _fit_ellipse_mask_from_contour(mask: Array, scale: float = 1.02) -> Tuple[Array, bool, str]:
    """
    Fit an ellipse to the outer contour and return an ellipse mask.
    scale > 1 expands ellipse slightly (useful to recover small border bites).
    """
    m = (mask > 0).astype(np.uint8) * 255
    h, w = m.shape[:2]
    contours, _ = cv.findContours(m, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_NONE)
    if not contours:
        return np.zeros_like(m, dtype=np.uint8), False, "no_contours"

    cnt = max(contours, key=cv.contourArea)
    if len(cnt) < 5:
        return m.copy(), False, "too_few_points_for_ellipse"

    (cx, cy), (MA, ma), angle = cv.fitEllipse(cnt)  # widths (full axis lengths)
    rx = max(1, int(round((MA * 0.5) * scale)))
    ry = max(1, int(round((ma * 0.5) * scale)))

    out = np.zeros((h, w), dtype=np.uint8)
    cv.ellipse(out, (int(round(cx)), int(round(cy))), (rx, ry), angle, 0, 360, 255, thickness=cv.FILLED)
    return out, True, "fitEllipse"

def _fit_ellipse_mask_from_ring_edges(
    g: Array,
    mask: Array,
    *,
    scale: float = 1.01,
    ring_width: int = 25,
) -> Tuple[Array, bool, str]:
    """
    Fit ellipse from Canny edges located in a thin ring around the mask border.
    This avoids bias from a truncated (bitten) filled region.
    """
    g = _to_uint8(g)
    m = (mask > 0).astype(np.uint8) * 255
    h, w = m.shape[:2]

    ring_width = max(5, int(ring_width))
    k = _ensure_odd(ring_width)
    se = cv.getStructuringElement(cv.MORPH_ELLIPSE, (k, k))

    dil = cv.dilate(m, se)
    ero = cv.erode(m, se)
    ring = cv.bitwise_and(dil, cv.bitwise_not(ero))  # border band

    # Auto Canny thresholds from median intensity INSIDE the mask
    inside = g[m > 0]
    if inside.size < 50:
        return np.zeros_like(m), False, "ring:too_few_inside_pixels"
    med = float(np.median(inside))
    lower = int(max(0, 0.66 * med))
    upper = int(min(255, 1.33 * med))

    edges = cv.Canny(g, lower, upper)
    edges = cv.bitwise_and(edges, ring)

    ys, xs = np.where(edges > 0)
    if ys.size < 80:
        return np.zeros_like(m), False, f"ring:not_enough_edge_points ({ys.size})"

    pts = np.stack([xs, ys], axis=1).astype(np.int32).reshape(-1, 1, 2)

    # fitEllipse needs >=5 points (we have plenty)
    (cx, cy), (MA, ma), angle = cv.fitEllipse(pts)

    rx = max(1, int(round((MA * 0.5) * scale)))
    ry = max(1, int(round((ma * 0.5) * scale)))

    out = np.zeros((h, w), dtype=np.uint8)
    cv.ellipse(out, (int(round(cx)), int(round(cy))), (rx, ry), angle, 0, 360, 255, thickness=cv.FILLED)
    return out, True, "ring:edge_fitEllipse"



def _should_use_ellipse(mask: Array, min_fill_ratio: float = 0.975) -> Tuple[bool, str]:
    """
    Detect the classic 'straight bite' problem:
    the shape is convex, so convex hull won't help, but area is noticeably below
    the best-fitting enclosing shape.

    We compare mask area vs minimum enclosing circle area.
    If the ratio is too low, it suggests a 'cut' happened.
    """
    m = (mask > 0).astype(np.uint8) * 255
    contours, _ = cv.findContours(m, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)
    if not contours:
        return False, "no_contours"

    cnt = max(contours, key=cv.contourArea)
    A = float(cv.contourArea(cnt))
    if A < 100:
        return False, "tiny_area"

    (x, y), r = cv.minEnclosingCircle(cnt)
    circle_area = float(np.pi * (r * r) + 1e-6)
    fill_ratio = A / circle_area

    if fill_ratio < min_fill_ratio:
        return True, f"low_fill_ratio_vs_enclosing_circle ({fill_ratio:.3f} < {min_fill_ratio:.3f})"
    return False, f"ok_fill_ratio ({fill_ratio:.3f})"


EllipseMode = Literal["off", "auto", "force"]

def _fit_ellipse_mask_from_radial_edges(
    g: Array,
    coarse_mask: Array,
    *,
    scale: float = 1.01,
    n_angles: int = 360,
    smooth_k: int = 9,
) -> Tuple[Array, bool, str]:
    """
    Fit an ellipse using boundary points detected from the ORIGINAL image (g),
    by finding the strongest outward intensity drop along radial rays.
    This is robust when the coarse mask has a 'chord' cut (Otsu/vignetting failure).
    """
    g = _to_uint8(g)
    m = (coarse_mask > 0).astype(np.uint8) * 255
    h, w = m.shape[:2]

    contours, _ = cv.findContours(m, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_NONE)
    if not contours:
        return np.zeros_like(m, dtype=np.uint8), False, "radial:no_contours"

    cnt = max(contours, key=cv.contourArea)
    if cv.contourArea(cnt) < 100:
        return np.zeros_like(m, dtype=np.uint8), False, "radial:tiny_area"

    # Use minEnclosingCircle center as a stable center guess (better than centroid when truncated)
    (cx, cy), r_guess = cv.minEnclosingCircle(cnt)
    cx = float(cx)
    cy = float(cy)
    r_guess = float(r_guess)

    if r_guess < 5:
        cx, cy = (w / 2.0), (h / 2.0)
        r_guess = 0.5 * min(h, w)

    # Smooth kernel for 1D profiles
    smooth_k = max(3, int(smooth_k))
    if smooth_k % 2 == 0:
        smooth_k += 1
    kernel = np.ones(smooth_k, dtype=np.float32) / float(smooth_k)

    pts = []

    for theta in np.linspace(0.0, 2.0 * np.pi, n_angles, endpoint=False):
        dx = float(np.cos(theta))
        dy = float(np.sin(theta))

        # Max radius until image boundary
        r_candidates = []
        if abs(dx) > 1e-6:
            r_candidates.append((0.0 - cx) / dx)
            r_candidates.append(((w - 1.0) - cx) / dx)
        if abs(dy) > 1e-6:
            r_candidates.append((0.0 - cy) / dy)
            r_candidates.append(((h - 1.0) - cy) / dy)

        r_candidates = [rr for rr in r_candidates if rr > 0]
        if not r_candidates:
            continue
        rmax = min(r_candidates)
        if rmax < 5:
            continue

        # Search window around guessed radius
        r_start = int(max(5, 0.55 * r_guess))
        r_end = int(min(rmax - 2, 1.25 * r_guess))
        if r_end <= r_start + 4:
            r_start = 1
            r_end = int(rmax - 2)

        rr = np.arange(r_start, r_end + 1, dtype=np.int32)
        xs = np.clip(np.rint(cx + rr * dx).astype(np.int32), 0, w - 1)
        ys = np.clip(np.rint(cy + rr * dy).astype(np.int32), 0, h - 1)

        prof = g[ys, xs].astype(np.float32)
        if prof.size < 6:
            continue

        # Smooth the profile to reduce vessel/noise spikes
        prof_s = np.convolve(prof, kernel, mode="same")

        # We want the strongest OUTWARD drop: inside(bright) -> outside(dark)
        drops = prof_s[:-1] - prof_s[1:]  # positive when going darker
        idx = int(np.argmax(drops))
        r_edge = int(rr[idx])

        x = int(np.clip(round(cx + r_edge * dx), 0, w - 1))
        y = int(np.clip(round(cy + r_edge * dy), 0, h - 1))
        pts.append([x, y])

    if len(pts) < 5:
        return np.zeros_like(m, dtype=np.uint8), False, "radial:too_few_points"

    pts_np = np.array(pts, dtype=np.int32).reshape(-1, 1, 2)
    (ecx, ecy), (MA, ma), angle = cv.fitEllipse(pts_np)

    rx = max(1, int(round((MA * 0.5) * scale)))
    ry = max(1, int(round((ma * 0.5) * scale)))

    out = np.zeros((h, w), dtype=np.uint8)
    cv.ellipse(
        out,
        (int(round(ecx)), int(round(ecy))),
        (rx, ry),
        angle,
        0,
        360,
        255,
        thickness=cv.FILLED,
    )
    return out, True, "radial:edge_drop_fitEllipse"



def compute_fov_mask(
    img_or_path: Union[str, Array],
    *,
    blur_ksize: int = 7,
    blur_kind: str = "median",     # "median" or "gaussian"
    close_ksize: Optional[int] = None,  # None => auto
    open_ksize: Optional[int] = None,   # None => auto
    do_hole_fill: bool = True,
    do_convex_hull: bool = True,
    ellipse_mode: EllipseMode = "auto",  # off / auto / force
    ellipse_scale: float = 1.02,         # slightly enlarge to recover small bites
    ellipse_min_fill_ratio: float = 0.975,
    return_debug: bool = False,
) -> Union[Array, Tuple[Array, FOVMaskDebug]]:
    """
    Compute a clean binary Field-Of-View (FOV) mask (0/255 uint8) for a fundus image.

    Fixes supported (exactly what we discussed):
      1) stronger closing (auto close/open sizes are bigger by default)
      2) convex hull (optional)
      3) ellipse fitting (robust for convex 'bites' that hull cannot fix)

    Returns:
      mask (uint8 0/255), and optionally debug object.
    """
    # Load if needed
    if isinstance(img_or_path, str):
        img = cv.imread(img_or_path, cv.IMREAD_UNCHANGED)
        if img is None:
            raise FileNotFoundError(f"Could not read image from path: {img_or_path}")
    else:
        img = img_or_path

    g = _to_gray_or_green(img)
    h, w = g.shape[:2]

    # Auto kernel sizes if not provided
    if close_ksize is None or open_ksize is None:
        auto_close, auto_open = _auto_ksizes(h, w)
        if close_ksize is None:
            close_ksize = auto_close
        if open_ksize is None:
            open_ksize = auto_open

    # Blur
    blur_ksize = _ensure_odd(blur_ksize)
    if blur_kind.lower() == "median":
        blurred = cv.medianBlur(g, blur_ksize)
    elif blur_kind.lower() == "gaussian":
        blurred = cv.GaussianBlur(g, (blur_ksize, blur_ksize), 0)
    else:
        raise ValueError("blur_kind must be 'median' or 'gaussian'.")
    g_corr = _flatfield_for_otsu(blurred)
    # Otsu threshold
    _, otsu = cv.threshold(g_corr, 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU)

    # Two candidates: otsu foreground or inverted foreground
    cand_a = otsu
    cand_b = cv.bitwise_not(otsu)

    # Morph cleanup each candidate (this is where close fixes bites)
    cand_a_m = _morph_cleanup(cand_a, close_ksize=close_ksize, open_ksize=open_ksize)
    cand_b_m = _morph_cleanup(cand_b, close_ksize=close_ksize, open_ksize=open_ksize)

    # Keep largest CC
    cand_a_l = _largest_connected_component(cand_a_m)
    cand_b_l = _largest_connected_component(cand_b_m)

    # Score both
    score_a = _candidate_score(cand_a_l)
    score_b = _candidate_score(cand_b_l)

    if score_b > score_a:
        chosen = cand_b_l
        chosen_inverted = True
        scores = {"normal": score_a, "inverted": score_b}
        after_morph = cand_b_m
    else:
        chosen = cand_a_l
        chosen_inverted = False
        scores = {"normal": score_a, "inverted": score_b}
        after_morph = cand_a_m

    filled = _fill_holes(chosen) if do_hole_fill else chosen.copy()
    hull = _convex_hull(filled) if do_convex_hull else filled.copy()

    # Ellipse handling (robust for convex straight "bites")
    ellipse_used = False
    ellipse_reason = "off"
    ellipse_mask = np.zeros_like(hull)

    if ellipse_mode == "force":
        ellipse_mask, ellipse_used, ellipse_reason = _fit_ellipse_mask_from_contour(hull, scale=ellipse_scale)
        final = ellipse_mask
    elif ellipse_mode == "auto":
        need, why = _should_use_ellipse(hull, min_fill_ratio=ellipse_min_fill_ratio)
        ellipse_reason = why
        if need:
            # NEW: fit from real image boundary (robust to the 'chord' failure)
            ellipse_mask, ellipse_used, fit_why = _fit_ellipse_mask_from_ring_edges(
                g_corr, hull, scale=ellipse_scale, ring_width=25
            )
            if ellipse_used:
                ellipse_reason = f"{ellipse_reason} | {fit_why}"
                final = ellipse_mask
            else:
                # fallback to your old contour-based ellipse
                ellipse_mask, ellipse_used, fit_why2 = _fit_ellipse_mask_from_contour(hull, scale=ellipse_scale)
                ellipse_reason = f"{ellipse_reason} | fallback:{fit_why2}"
                final = ellipse_mask if ellipse_used else hull
        else:
            final = hull

    else:  # "off"
        final = hull

    final = (final > 0).astype(np.uint8) * 255

    if not return_debug:
        return final

    dbg = FOVMaskDebug(
        green_or_gray=g,
        blurred=blurred,
        otsu=otsu,
        candidate_chosen=chosen,
        after_morph=after_morph,
        largest_cc=chosen,
        filled=filled,
        convex_hull=hull,
        ellipse_mask=ellipse_mask,
        final=final,
        chosen_inverted=chosen_inverted,
        scores=scores,
        ellipse_used=ellipse_used,
        ellipse_reason=ellipse_reason,
    )
    return final, dbg


import os
from pathlib import Path
import cv2 as cv

img_path = Path("images/input/4.png")

print("cwd =", os.getcwd())
print("relative exists? =", img_path.exists())
print("absolute path =", img_path.resolve())
print("absolute exists? =", img_path.resolve().exists())

# OpenCV check
abs_path = str(img_path.resolve())
print("cv.haveImageReader =", cv.haveImageReader(abs_path))
img = cv.imread(abs_path, cv.IMREAD_UNCHANGED)
print("cv.imread is None? =", img is None)




import cv2 as cv
from matplotlib import pyplot as plt
from pathlib import Path
import os

from fov_mask import compute_fov_mask

def find_project_root(start: Path | None = None) -> Path:
    p = (start or Path.cwd()).resolve()
    for _ in range(25):
        if (p / "images" / "input").exists():
            return p
        if p.parent == p:
            break
        p = p.parent
    raise FileNotFoundError("Couldn't find a folder containing images/input")

ROOT = find_project_root()  # <- keep this, DO NOT use .parent
print("cwd =", Path.cwd().resolve())
print("ROOT =", ROOT)

img_path = ROOT / "images" / "input" / "14.png"
print("img_path =", img_path)
print("exists? =", img_path.exists())

img = cv.imread(str(img_path), cv.IMREAD_UNCHANGED)
if img is None:
    raise FileNotFoundError(f"OpenCV could not read: {img_path}")

mask, dbg = compute_fov_mask(
    img,
    close_ksize=21,
    open_ksize=11,
    do_convex_hull=True,
    ellipse_mode="auto",
    ellipse_scale=1.01,
    return_debug=True
)

plt.figure(figsize=(18,4))
plt.subplot(1,5,1); plt.title("Green/Gray");  plt.imshow(dbg.green_or_gray, cmap="gray"); plt.axis("off")
plt.subplot(1,5,2); plt.title("Otsu");        plt.imshow(dbg.otsu, cmap="gray");          plt.axis("off")
plt.subplot(1,5,3); plt.title("Largest CC");  plt.imshow(dbg.largest_cc, cmap="gray");    plt.axis("off")
plt.subplot(1,5,4); plt.title("Convex hull"); plt.imshow(dbg.convex_hull, cmap="gray");   plt.axis("off")
plt.subplot(1,5,5); plt.title("Final");       plt.imshow(mask, cmap="gray");              plt.axis("off")
plt.show()

print("Chosen inverted:", dbg.chosen_inverted)
print("Scores:", dbg.scores)
print("Ellipse used:", dbg.ellipse_used)
print("Ellipse reason:", dbg.ellipse_reason)



%%writefile vessel_pipeline_c.py
from __future__ import annotations

from dataclasses import dataclass
from typing import Dict, Optional, Tuple, Union, Literal, Any

import numpy as np
import cv2 as cv

from fov_mask import compute_fov_mask

Array = np.ndarray
ThresholdMode = Literal["otsu", "adaptive"]
EnhanceMode = Literal["blackhat", "tophat_invert"]


@dataclass
class VesselSegDebug:
    bgr: Array
    fov_mask: Array
    green: Array
    green_in_fov: Array
    clahe: Array
    vesselness: Array
    binary_raw: Array
    binary_clean: Array
    final: Array
    params: Dict[str, Any]
    stats: Dict[str, Any]


def _to_uint8(img: Array) -> Array:
    if img.dtype == np.uint8:
        return img
    x = img.astype(np.float32)
    x = x - float(x.min())
    denom = float(x.max() - x.min())
    if denom < 1e-6:
        denom = 1.0
    x = (255.0 * x / denom).clip(0, 255).astype(np.uint8)
    return x


def _ensure_odd(k: int) -> int:
    k = int(k)
    if k < 1:
        k = 1
    if k % 2 == 0:
        k += 1
    return k


def _line_se(length: int, angle_deg: float, thickness: int = 1) -> Array:
    """
    Create a line-shaped structuring element (0/1 uint8) by drawing a line
    on a square canvas. Used for oriented morphological black-hat/top-hat.
    """
    length = int(max(3, length))
    thickness = int(max(1, thickness))
    k = np.zeros((length, length), dtype=np.uint8)

    c = (length - 1) / 2.0
    rad = np.deg2rad(angle_deg)

    dx = (length * 0.45) * np.cos(rad)
    dy = (length * 0.45) * np.sin(rad)

    x0 = int(round(c - dx))
    y0 = int(round(c - dy))
    x1 = int(round(c + dx))
    y1 = int(round(c + dy))

    cv.line(k, (x0, y0), (x1, y1), 1, thickness=thickness)
    return k


def _otsu_threshold_from_values(values_uint8: Array) -> int:
    """
    Otsu threshold computed ONLY from the provided 0..255 uint8 values.
    This avoids bias from pixels outside the FOV mask.
    """
    v = values_uint8.reshape(-1).astype(np.uint8)
    if v.size == 0:
        return 128

    hist = np.bincount(v, minlength=256).astype(np.float64)
    total = float(v.size)

    sum_total = float(np.dot(np.arange(256), hist))
    sum_b = 0.0
    w_b = 0.0
    max_var = -1.0
    thr = 128

    for t in range(256):
        w_b += hist[t]
        if w_b <= 0:
            continue
        w_f = total - w_b
        if w_f <= 0:
            break
        sum_b += float(t) * hist[t]
        m_b = sum_b / w_b
        m_f = (sum_total - sum_b) / w_f
        between = w_b * w_f * (m_b - m_f) * (m_b - m_f)
        if between > max_var:
            max_var = between
            thr = t

    return int(thr)


def _remove_small_components(mask_01: Array, min_area: int) -> Tuple[Array, Dict[str, Any]]:
    """
    Keep only connected components with area >= min_area.
    Input: 0/1 uint8.
    Output: 0/1 uint8.
    """
    m = (mask_01 > 0).astype(np.uint8)
    num, labels, stats, _ = cv.connectedComponentsWithStats(m, connectivity=8)
    kept = np.zeros_like(m, dtype=np.uint8)

    kept_count = 0
    removed_count = 0
    areas_kept = []

    for i in range(1, num):
        area = int(stats[i, cv.CC_STAT_AREA])
        if area >= int(min_area):
            kept[labels == i] = 1
            kept_count += 1
            areas_kept.append(area)
        else:
            removed_count += 1

    info = {
        "cc_total": int(num - 1),
        "cc_kept": int(kept_count),
        "cc_removed": int(removed_count),
        "min_area": int(min_area),
        "areas_kept_min": int(min(areas_kept)) if areas_kept else 0,
        "areas_kept_max": int(max(areas_kept)) if areas_kept else 0,
    }
    return kept, info


def segment_vessels_pipeline_c(
    img_bgr_or_gray: Array,
    *,
    # FOV mask params (you can tune these)
    fov_close_ksize: Optional[int] = None,
    fov_open_ksize: Optional[int] = None,
    fov_blur_ksize: int = 7,
    fov_blur_kind: str = "median",
    fov_do_convex_hull: bool = True,
    fov_ellipse_mode: str = "auto",
    fov_ellipse_scale: float = 1.01,
    # Pipeline C params
    clahe_clip_limit: float = 2.0,
    clahe_tile_grid_size: int = 8,
    enhance_mode: EnhanceMode = "blackhat",
    line_lengths: Tuple[int, ...] = (9, 13, 17),
    line_thickness: int = 1,
    n_angles: int = 12,  # 12 -> 0..165 step 15 deg
    add_disk_blackhat: bool = True,
    disk_sizes: Tuple[int, ...] = (9, 13),
    threshold_mode: ThresholdMode = "otsu",
    otsu_offset: int = -5,  # negative => more sensitive
    adaptive_block_size: int = 31,
    adaptive_C: int = -2,
    morph_open_ksize: int = 3,
    morph_close_ksize: int = 5,
    min_cc_area: int = 30,
    verbose: bool = False,
    return_debug: bool = False,
) -> Union[Array, Tuple[Array, VesselSegDebug]]:
    """
    Pipeline C (OpenCV-only baseline):
      - FOV mask
      - green channel
      - CLAHE
      - vessel enhancement via morphology (black-hat / top-hat after inversion)
        with multi-orientation line kernels (+ optional disk black-hat)
      - threshold (Otsu on FOV pixels OR adaptive)
      - cleanup (open/close + remove small CCs)
    Returns uint8 0/255 mask.
    """
    if img_bgr_or_gray is None:
        raise ValueError("img_bgr_or_gray is None")

    img = img_bgr_or_gray
    if img.ndim == 2:
        bgr = cv.cvtColor(_to_uint8(img), cv.COLOR_GRAY2BGR)
    elif img.ndim == 3 and img.shape[2] >= 3:
        bgr = _to_uint8(img[:, :, :3])
    else:
        raise ValueError(f"Unsupported image shape: {img.shape}")

    h, w = bgr.shape[:2]

    # --- FOV mask ---
    fov_mask = compute_fov_mask(
        bgr,
        blur_ksize=fov_blur_ksize,
        blur_kind=fov_blur_kind,
        close_ksize=fov_close_ksize,
        open_ksize=fov_open_ksize,
        do_convex_hull=fov_do_convex_hull,
        ellipse_mode=fov_ellipse_mode,   # "off"/"auto"/"force"
        ellipse_scale=fov_ellipse_scale,
        return_debug=False,
    )
    fov01 = (fov_mask > 0).astype(np.uint8)
    fov_area_ratio = float(fov01.mean())

    # green channel (fundus: green has best vessel contrast)
    green = bgr[:, :, 1].copy()
    green_in_fov = green.copy()
    green_in_fov[fov01 == 0] = 0

    # --- CLAHE inside FOV (avoid amplifying outside background) ---
    tile = int(max(2, clahe_tile_grid_size))
    clahe = cv.createCLAHE(clipLimit=float(clahe_clip_limit), tileGridSize=(tile, tile))
    clahe_img = clahe.apply(green)

    clahe_in_fov = clahe_img.copy()
    clahe_in_fov[fov01 == 0] = 0

    # --- Vessel enhancement (multi-orientation morphology) ---
    angles = np.linspace(0, 180, num=int(max(2, n_angles)), endpoint=False)

    vesselness = np.zeros((h, w), dtype=np.uint8)

    def apply_enhancement(src_u8: Array, se: Array) -> Array:
        if enhance_mode == "blackhat":
            return cv.morphologyEx(src_u8, cv.MORPH_BLACKHAT, se)
        elif enhance_mode == "tophat_invert":
            inv = cv.bitwise_not(src_u8)
            return cv.morphologyEx(inv, cv.MORPH_TOPHAT, se)
        else:
            raise ValueError("enhance_mode must be 'blackhat' or 'tophat_invert'")

    # oriented lines
    for L in line_lengths:
        L = int(max(3, L))
        for a in angles:
            se = _line_se(L, float(a), thickness=line_thickness)
            resp = apply_enhancement(clahe_in_fov, se)
            vesselness = cv.max(vesselness, resp)

    # optional isotropic disk black-hat (helps thick vessels)
    if add_disk_blackhat:
        for d in disk_sizes:
            d = int(max(3, d))
            se = cv.getStructuringElement(cv.MORPH_ELLIPSE, (d, d))
            resp = apply_enhancement(clahe_in_fov, se)
            vesselness = cv.max(vesselness, resp)

    vesselness[fov01 == 0] = 0

    # small denoise
    vesselness = cv.GaussianBlur(vesselness, (3, 3), 0)

    # --- Threshold ---
    if threshold_mode == "otsu":
        vals = vesselness[fov01 > 0]
        thr = _otsu_threshold_from_values(vals)
        thr2 = int(np.clip(thr + int(otsu_offset), 0, 255))
        binary01 = (vesselness >= thr2).astype(np.uint8)
        thr_used = thr2
    elif threshold_mode == "adaptive":
        bs = _ensure_odd(adaptive_block_size)
        thr_img = cv.adaptiveThreshold(
            vesselness,
            255,
            cv.ADAPTIVE_THRESH_GAUSSIAN_C,
            cv.THRESH_BINARY,
            bs,
            int(adaptive_C),
        )
        binary01 = (thr_img > 0).astype(np.uint8)
        thr_used = {"adaptive_block_size": bs, "adaptive_C": int(adaptive_C)}
    else:
        raise ValueError("threshold_mode must be 'otsu' or 'adaptive'")

    binary01[fov01 == 0] = 0

    # --- Cleanup ---
    ok_open = _ensure_odd(morph_open_ksize)
    ok_close = _ensure_odd(morph_close_ksize)
    k_open = cv.getStructuringElement(cv.MORPH_ELLIPSE, (ok_open, ok_open))
    k_close = cv.getStructuringElement(cv.MORPH_ELLIPSE, (ok_close, ok_close))

    bin255 = (binary01 * 255).astype(np.uint8)
    bin255 = cv.morphologyEx(bin255, cv.MORPH_OPEN, k_open)
    bin255 = cv.morphologyEx(bin255, cv.MORPH_CLOSE, k_close)
    binary01_clean = (bin255 > 0).astype(np.uint8)

    binary01_clean, cc_info = _remove_small_components(binary01_clean, min_area=min_cc_area)
    binary01_clean[fov01 == 0] = 0

    final = (binary01_clean * 255).astype(np.uint8)

    # --- Debug prints ---
    if verbose:
        vvals = vesselness[fov01 > 0]
        vmin = int(vvals.min()) if vvals.size else 0
        vmax = int(vvals.max()) if vvals.size else 0
        vmean = float(vvals.mean()) if vvals.size else 0.0
        fg_raw = int(binary01.sum())
        fg_clean = int(binary01_clean.sum())

        print("[PipelineC] shape =", (h, w), "FOV_area_ratio =", round(fov_area_ratio, 4))
        print("[PipelineC] CLAHE clipLimit =", clahe_clip_limit, "tile =", tile)
        print("[PipelineC] enhance_mode =", enhance_mode,
              "| line_lengths =", line_lengths, "line_thickness =", line_thickness,
              "n_angles =", int(n_angles),
              "| add_disk_blackhat =", bool(add_disk_blackhat), "disk_sizes =", disk_sizes)
        print("[PipelineC] vesselness stats (in FOV): min/max/mean =", vmin, "/", vmax, "/", round(vmean, 3))
        print("[PipelineC] threshold_mode =", threshold_mode, "| thr_used =", thr_used)
        print("[PipelineC] foreground px raw =", fg_raw, "| after clean =", fg_clean)
        print("[PipelineC] CC info:", cc_info)

    if not return_debug:
        return final

    dbg = VesselSegDebug(
        bgr=bgr,
        fov_mask=(fov01 * 255).astype(np.uint8),
        green=green,
        green_in_fov=green_in_fov,
        clahe=clahe_in_fov,
        vesselness=vesselness,
        binary_raw=(binary01 * 255).astype(np.uint8),
        binary_clean=(binary01_clean * 255).astype(np.uint8),
        final=final,
        params={
            "clahe_clip_limit": clahe_clip_limit,
            "clahe_tile_grid_size": clahe_tile_grid_size,
            "enhance_mode": enhance_mode,
            "line_lengths": line_lengths,
            "line_thickness": line_thickness,
            "n_angles": n_angles,
            "add_disk_blackhat": add_disk_blackhat,
            "disk_sizes": disk_sizes,
            "threshold_mode": threshold_mode,
            "otsu_offset": otsu_offset,
            "adaptive_block_size": adaptive_block_size,
            "adaptive_C": adaptive_C,
            "morph_open_ksize": morph_open_ksize,
            "morph_close_ksize": morph_close_ksize,
            "min_cc_area": min_cc_area,
        },
        stats={
            "fov_area_ratio": fov_area_ratio,
            "thr_used": thr_used,
            **cc_info,
        },
    )
    return final, dbg


def vessel_segmentation(input_image_path: Union[str, "os.PathLike[str]"], *, verbose: bool = False) -> Array:
    """
    Drop-in replacement for the course skeleton: reads path, returns 0/255 uint8 segmentation.
    """
    img = cv.imread(str(input_image_path), cv.IMREAD_COLOR)
    if img is None:
        raise FileNotFoundError(f"Could not read image: {input_image_path}")

    seg = segment_vessels_pipeline_c(
        img,
        # reasonable defaults for DRIVE-like images
        clahe_clip_limit=2.0,
        clahe_tile_grid_size=8,
        enhance_mode="blackhat",
        line_lengths=(9, 13, 17),
        n_angles=12,
        add_disk_blackhat=True,
        disk_sizes=(9, 13),
        threshold_mode="otsu",
        otsu_offset=-5,
        morph_open_ksize=3,
        morph_close_ksize=5,
        min_cc_area=30,
        verbose=verbose,
        return_debug=False,
    )
    return seg

import os
from pathlib import Path
import cv2 as cv
from matplotlib import pyplot as plt

from vessel_pipeline_c import vessel_segmentation  # <- uses Pipeline C

# Dataset paths (project-local)
ROOT = find_project_root()
img_path = ROOT / "images" / "input"
gt_path = ROOT / "images" / "gt"

print("ROOT:", ROOT)
print("Input dir:", img_path, "| exists:", img_path.exists())
print("GT dir:", gt_path, "| exists:", gt_path.exists())


def single_IoU(img_name: str) -> float:
    input_img = img_path / img_name
    if not input_img.exists():
        raise FileNotFoundError(f"Could not find input image: {input_img}")

    obtained = vessel_segmentation(str(input_img), verbose=False)

    target_img = gt_path / img_name
    solution = cv.imread(str(target_img), cv.IMREAD_GRAYSCALE)
    if solution is None:
        raise FileNotFoundError(f"Could not read ground-truth: {target_img}")

    # ensure binary 0/255
    obtained = (obtained > 0).astype("uint8") * 255
    solution = (solution > 0).astype("uint8") * 255

    print(f"[DBG] {img_name} | obtained shape={obtained.shape} unique={sorted(set(obtained.ravel().tolist()))[:5]}")
    print(f"[DBG] {img_name} | solution shape={solution.shape} unique={sorted(set(solution.ravel().tolist()))[:5]}")

    plt.imshow(obtained, cmap="gray")
    plt.title(f"Obtained: {img_name}")
    plt.axis("off")
    plt.show()

    intersectionAB = cv.countNonZero(cv.bitwise_and(obtained, solution))
    unionAB = cv.countNonZero(cv.bitwise_or(obtained, solution))
    score = float(intersectionAB) / float(unionAB + 1e-9)

    print(f"Image {img_name} - IoU={score:.6f}")
    return score


# Evaluate all images
meanIoU = 0.0
imgs = sorted([p.name for p in img_path.iterdir() if p.suffix.lower() == ".png"])
print("Images:", imgs)

for img in imgs:
    meanIoU += single_IoU(img)

meanIoU /= max(1, len(imgs))
print("------------------------------------")
print(f"Mean IoU={meanIoU:.6f}")


# === Grid search (hand-picked combos) for Pipeline C ===
# Shows overlays + prints params + per-image IoU + summary ranking.

import time
import numpy as np
import cv2 as cv
import pandas as pd
from pathlib import Path
from matplotlib import pyplot as plt

from vessel_pipeline_c import segment_vessels_pipeline_c  # uses compute_fov_mask internally


# -----------------------------
# Helpers
# -----------------------------
def find_project_root(start: Path | None = None) -> Path:
    p = (start or Path.cwd()).resolve()
    for _ in range(30):
        if (p / "images" / "input").exists() and (p / "images" / "gt").exists():
            return p
        if p.parent == p:
            break
        p = p.parent
    raise FileNotFoundError("Couldn't find a folder containing images/input and images/gt")

def bin255(x: np.ndarray) -> np.ndarray:
    return (x > 0).astype(np.uint8) * 255

def iou(pred255: np.ndarray, gt255: np.ndarray) -> float:
    p = (pred255 > 0)
    g = (gt255 > 0)
    inter = np.logical_and(p, g).sum()
    union = np.logical_or(p, g).sum()
    return float(inter) / float(union + 1e-9)

def overlay_rg(pred255: np.ndarray, gt255: np.ndarray) -> np.ndarray:
    # RED=pred, GREEN=gt, YELLOW=overlap
    p = (pred255 > 0).astype(np.uint8) * 255
    g = (gt255 > 0).astype(np.uint8) * 255
    out = np.zeros((pred255.shape[0], pred255.shape[1], 3), dtype=np.uint8)
    out[..., 2] = 0          # B
    out[..., 1] = g          # G
    out[..., 0] = p          # R
    return out

def show_grid(images, titles, ncols=5, figsize=(18, 12), suptitle=None):
    n = len(images)
    ncols = int(ncols)
    nrows = int(np.ceil(n / ncols))
    plt.figure(figsize=figsize)
    for i in range(n):
        plt.subplot(nrows, ncols, i + 1)
        img = images[i]
        if img.ndim == 2:
            plt.imshow(img, cmap="gray")
        else:
            plt.imshow(img)
        plt.title(titles[i], fontsize=9)
        plt.axis("off")
    if suptitle:
        plt.suptitle(suptitle, fontsize=14)
    plt.tight_layout()
    plt.show()


# -----------------------------
# Dataset
# -----------------------------
ROOT = find_project_root()
inp_dir = ROOT / "images" / "input"
gt_dir  = ROOT / "images" / "gt"

imgs = sorted([p.name for p in inp_dir.iterdir() if p.suffix.lower() == ".png"])
if not imgs:
    raise FileNotFoundError(f"No .png images found in: {inp_dir}")

print("ROOT:", ROOT)
print("Num images:", len(imgs))
print("Images:", imgs)


# -----------------------------
# Hand-picked parameter combinations (designed to move IoU)
# -----------------------------
# Notes on what each combo is trying to do:
# - "sensitive_thin": more angles + smaller CC removal + more negative otsu_offset => more thin vessels (but more FP risk)
# - "balanced_plus": slightly more sensitivity + stronger closing to reconnect fragments
# - "precision_fp": less sensitivity + stronger opening + bigger CC threshold => reduce false positives
# - "tophat_invert": alternative enhancement mode (sometimes better on certain illumination)
# - "adaptive_thr": sometimes rescues cases where global Otsu is unstable
# - "strong_clahe": boosts local contrast (can help thin vessels, can also amplify noise)
# - "thick_bias": stronger disk kernels + longer lines to emphasize thick vessels
# - "fov_tight": tighter FOV (can reduce rim artifacts -> better IoU if rim FP is common)
COMBOS = [
    dict(
        name="baseline",
        params=dict(
            clahe_clip_limit=2.0,
            clahe_tile_grid_size=8,
            enhance_mode="blackhat",
            line_lengths=(9, 13, 17),
            line_thickness=1,
            n_angles=12,
            add_disk_blackhat=True,
            disk_sizes=(9, 13),
            threshold_mode="otsu",
            otsu_offset=-5,
            morph_open_ksize=3,
            morph_close_ksize=5,
            min_cc_area=30,
        )
    ),
    dict(
        name="sensitive_thin",
        params=dict(
            clahe_clip_limit=2.5,
            clahe_tile_grid_size=8,
            enhance_mode="blackhat",
            line_lengths=(7, 11, 15, 19),
            line_thickness=1,
            n_angles=16,
            add_disk_blackhat=True,
            disk_sizes=(7, 11),
            threshold_mode="otsu",
            otsu_offset=-9,
            morph_open_ksize=3,
            morph_close_ksize=7,
            min_cc_area=10,
        )
    ),
    dict(
        name="balanced_plus",
        params=dict(
            clahe_clip_limit=2.0,
            clahe_tile_grid_size=8,
            enhance_mode="blackhat",
            line_lengths=(9, 13, 17, 21),
            line_thickness=1,
            n_angles=16,
            add_disk_blackhat=True,
            disk_sizes=(9, 13),
            threshold_mode="otsu",
            otsu_offset=-7,
            morph_open_ksize=3,
            morph_close_ksize=7,
            min_cc_area=20,
        )
    ),
    dict(
        name="precision_fp",
        params=dict(
            clahe_clip_limit=1.8,
            clahe_tile_grid_size=8,
            enhance_mode="blackhat",
            line_lengths=(11, 15, 19),
            line_thickness=1,
            n_angles=12,
            add_disk_blackhat=True,
            disk_sizes=(11, 15),
            threshold_mode="otsu",
            otsu_offset=-3,
            morph_open_ksize=5,
            morph_close_ksize=5,
            min_cc_area=45,
        )
    ),
    dict(
        name="tophat_invert",
        params=dict(
            clahe_clip_limit=2.0,
            clahe_tile_grid_size=8,
            enhance_mode="tophat_invert",
            line_lengths=(9, 13, 17),
            line_thickness=1,
            n_angles=12,
            add_disk_blackhat=False,
            disk_sizes=(9, 13),
            threshold_mode="otsu",
            otsu_offset=-5,
            morph_open_ksize=3,
            morph_close_ksize=5,
            min_cc_area=25,
        )
    ),
    dict(
        name="adaptive_thr",
        params=dict(
            clahe_clip_limit=2.0,
            clahe_tile_grid_size=8,
            enhance_mode="blackhat",
            line_lengths=(9, 13, 17),
            line_thickness=1,
            n_angles=12,
            add_disk_blackhat=True,
            disk_sizes=(9, 13),
            threshold_mode="adaptive",
            adaptive_block_size=41,
            adaptive_C=-3,
            morph_open_ksize=3,
            morph_close_ksize=5,
            min_cc_area=25,
        )
    ),
    dict(
        name="strong_clahe",
        params=dict(
            clahe_clip_limit=3.5,
            clahe_tile_grid_size=8,
            enhance_mode="blackhat",
            line_lengths=(9, 13, 17),
            line_thickness=1,
            n_angles=12,
            add_disk_blackhat=True,
            disk_sizes=(9, 13),
            threshold_mode="otsu",
            otsu_offset=-6,
            morph_open_ksize=3,
            morph_close_ksize=5,
            min_cc_area=25,
        )
    ),
    dict(
        name="thick_bias",
        params=dict(
            clahe_clip_limit=2.0,
            clahe_tile_grid_size=8,
            enhance_mode="blackhat",
            line_lengths=(11, 15, 19),
            line_thickness=1,
            n_angles=12,
            add_disk_blackhat=True,
            disk_sizes=(11, 15, 19),
            threshold_mode="otsu",
            otsu_offset=-6,
            morph_open_ksize=3,
            morph_close_ksize=5,
            min_cc_area=25,
        )
    ),
    dict(
        name="fov_tight",
        params=dict(
            # Only FOV tweaks + mild sensitivity (often reduces rim false positives)
            fov_close_ksize=31,
            fov_open_ksize=13,
            fov_blur_ksize=7,
            fov_blur_kind="median",
            fov_do_convex_hull=True,
            fov_ellipse_mode="auto",
            fov_ellipse_scale=1.00,

            clahe_clip_limit=2.0,
            clahe_tile_grid_size=8,
            enhance_mode="blackhat",
            line_lengths=(9, 13, 17),
            line_thickness=1,
            n_angles=12,
            add_disk_blackhat=True,
            disk_sizes=(9, 13),
            threshold_mode="otsu",
            otsu_offset=-5,
            morph_open_ksize=3,
            morph_close_ksize=5,
            min_cc_area=30,
        )
    ),
]


# -----------------------------
# Run all combos
# -----------------------------
ALL_RESULTS = []  # list of dict rows for ranking

# If you want to run faster while tuning, set e.g. MAX_IMAGES=6
MAX_IMAGES = None  # None => use all images
eval_imgs = imgs if MAX_IMAGES is None else imgs[:MAX_IMAGES]

for ci, combo in enumerate(COMBOS, start=1):
    name = combo["name"]
    params = combo["params"]

    print("\n" + "="*90)
    print(f"[{ci}/{len(COMBOS)}] COMBO: {name}")
    print("Params:")
    for k in sorted(params.keys()):
        print(f"  - {k}: {params[k]}")

    per_image = []
    overlays = []
    titles = []

    t0 = time.perf_counter()

    for img_name in eval_imgs:
        in_path = inp_dir / img_name
        gt_path = gt_dir / img_name

        img = cv.imread(str(in_path), cv.IMREAD_COLOR)
        if img is None:
            print(f"[WARN] Could not read input: {in_path}")
            continue

        gt = cv.imread(str(gt_path), cv.IMREAD_GRAYSCALE)
        if gt is None:
            print(f"[WARN] Could not read GT: {gt_path}")
            continue

        pred = segment_vessels_pipeline_c(
            img,
            verbose=False,
            return_debug=False,
            **params
        )

        pred = bin255(pred)
        gt = bin255(gt)

        sc = iou(pred, gt)
        per_image.append(dict(image=img_name, iou=sc))
        overlays.append(overlay_rg(pred, gt))
        titles.append(f"{img_name}\nIoU={sc:.4f}")

    t1 = time.perf_counter()
    df = pd.DataFrame(per_image).sort_values("image").reset_index(drop=True)

    if len(df) == 0:
        print("[ERROR] No images were evaluated for this combo.")
        continue

    mean_iou = float(df["iou"].mean())
    med_iou  = float(df["iou"].median())
    std_iou  = float(df["iou"].std(ddof=0))
    min_iou  = float(df["iou"].min())
    max_iou  = float(df["iou"].max())
    sec_per_img = (t1 - t0) / max(1, len(df))

    print("\nSummary:")
    print(f"  mean IoU  = {mean_iou:.6f}")
    print(f"  median    = {med_iou:.6f}")
    print(f"  std       = {std_iou:.6f}")
    print(f"  min / max = {min_iou:.6f} / {max_iou:.6f}")
    print(f"  time/img  = {sec_per_img:.3f} s")

    # Print per-image IoU table
    display(df)

    # Show overlays grid (RED=pred, GREEN=GT, YELLOW=overlap)
    show_grid(
        overlays,
        titles,
        ncols=5,
        figsize=(18, 12),
        suptitle=f"{name} | mean IoU={mean_iou:.4f} | RED=Pred, GREEN=GT, YELLOW=Overlap"
    )

    # Optional: show internal debug stats for the "median IoU" image (good representative)
    rep_row = df.iloc[int(len(df) // 2)]
    rep_name = rep_row["image"]
    rep_img = cv.imread(str(inp_dir / rep_name), cv.IMREAD_COLOR)

    seg_rep, dbg = segment_vessels_pipeline_c(rep_img, return_debug=True, verbose=False, **params)
    print(f"[Representative debug] image={rep_name} | IoU={float(rep_row['iou']):.4f}")
    print("  dbg.stats:", dbg.stats)
    print("  dbg.params:", dbg.params)

    # Save ranking row
    ALL_RESULTS.append(dict(
        combo=name,
        mean_iou=mean_iou,
        median_iou=med_iou,
        std_iou=std_iou,
        min_iou=min_iou,
        max_iou=max_iou,
        time_per_img_s=sec_per_img
    ))

# Final ranking
rank = pd.DataFrame(ALL_RESULTS).sort_values(["mean_iou", "median_iou"], ascending=False).reset_index(drop=True)
print("\n" + "#"*90)
print("RANKING (sorted by mean IoU desc):")
display(rank)

