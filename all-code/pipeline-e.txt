# Project: Retinal vessel segmentation

The segmentation of retinal blood vessels from eye fundus images is of great significance for early diagnosis of eye-related diseases such as diabetes and hypertension.

The goal of this project is to read an eye fundus image like the following:
![](https://dlsi.ua.es/~pertusa/tvainput21.png)

And extract the blood vessels as can be seen in the corresponding ground-truth sample:

![](https://dlsi.ua.es/~pertusa/tvagt21.png)

All the images for this project are extracted from the [Drive](https://drive.grand-challenge.org) dataset.

For this task you can use any computer vision technique **except by deep neural networks, that are not allowed in this project**.

## Implementation

To begin with the project, first download from moodle the folder with all the images and upload it to google drive.

Then, import the following libraries (you can add more):



import os
from google.colab import drive
import cv2 as cv

drive.mount('/content/drive')

%matplotlib inline
from matplotlib import pyplot as plt

db_path =  "/content/drive/MyDrive/TVAProject"


Now you should edit the following function to segment the image and return the obtained segmentation. This is only a simple (basic) skeleton that obviously is not performing well. Your project's goal is basically to complete this function. You can read the attached papers in Moodle to get ideas for the segmentation.


def vessel_segmentation(input_image):

    img = cv.imread(input_image, cv.IMREAD_GRAYSCALE)

    # TODO: Here it goes your segmentation algorithm. A basic threholding is shown as example.
    th, segmented_image = cv.threshold(img, 128, 255, cv.THRESH_BINARY)

    return segmented_image





Your project will be evaluated with the Intersection over Union (IoU) metric, commonly used in segmentation tasks. This is the function to read a ground truth image and return the IoU considering your segmented image.





def single_IoU(img_name):

    # Apply segmentation
    input_img = os.path.join(db_path, 'input', img_name)
    obtained = vessel_segmentation(input_img)

    # Path of the target (ground truth) image
    path_target = os.path.join(db_path, 'gt', img_name)
    solution = cv.imread(path_target, cv.IMREAD_GRAYSCALE)

    # Show obtained results
    plt.imshow(obtained, cmap=plt.get_cmap('gray'))
    plt.show()

    # IoU calculation
    intersectionAB = cv.countNonZero(obtained & solution)
    unionAB = cv.countNonZero(obtained | solution)
    score = intersectionAB / unionAB
    print("Image {} - IoU={}".format(path_input, score))

    return score






This is the evaluation method that reads all the images from the input folder and gets the mean IoU for all of them. This is the score of your project, the higher the better.



meanIoU=0

path_input = os.path.join(db_path, 'input')

# List images in input folder
imgs = [f for f in os.listdir(path_input) if f.endswith('.png')]
print(imgs)

# For each image
for img in imgs:
    meanIoU += single_IoU(img)

# Average
meanIoU /= len(imgs)
print("------------------------------------")
print("Mean IoU={}".format(meanIoU))


%%writefile fov_mask.py
from __future__ import annotations

from dataclasses import dataclass
from typing import Dict, Optional, Tuple, Union, Literal

import numpy as np
import cv2 as cv

Array = np.ndarray


@dataclass
class FOVMaskDebug:
    """Optional debug outputs to inspect intermediate steps."""
    green_or_gray: Array
    blurred: Array
    otsu: Array
    candidate_chosen: Array
    after_morph: Array
    largest_cc: Array
    filled: Array
    convex_hull: Array
    ellipse_mask: Array
    final: Array
    chosen_inverted: bool
    scores: Dict[str, float]
    ellipse_used: bool
    ellipse_reason: str


def _to_uint8(gray: Array) -> Array:
    if gray.dtype == np.uint8:
        return gray
    g = gray.astype(np.float32)
    g = g - g.min()
    denom = (g.max() - g.min()) if (g.max() - g.min()) > 1e-6 else 1.0
    return (255.0 * g / denom).clip(0, 255).astype(np.uint8)

def _flatfield_for_otsu(g: Array) -> Array:
    """
    Remove slow illumination gradients (vignetting) so global thresholding
    doesn't 'eat' the dark retinal rim.
    """
    h, w = g.shape[:2]
    sigma = 0.12 * float(min(h, w))  # large blur = illumination field
    bg = cv.GaussianBlur(g, (0, 0), sigmaX=sigma, sigmaY=sigma)

    # flat-field: g / bg
    corr = cv.divide(g, bg, scale=255.0)
    corr = cv.normalize(corr, None, 0, 255, cv.NORM_MINMAX)
    return corr.astype(np.uint8)


def _to_gray_or_green(img: Array) -> Array:
    """
    Convert input (BGR/RGB/GRAY) to a single-channel image.
    For fundus images, green channel usually gives best contrast.
    """
    if img is None:
        raise ValueError("Input image is None.")
    if img.ndim == 2:
        gray = img
    elif img.ndim == 3 and img.shape[2] >= 3:
        # OpenCV loads as BGR by default
        gray = img[:, :, 1]  # green channel
    else:
        raise ValueError(f"Unsupported image shape: {img.shape}")
    return _to_uint8(gray)


def _ensure_odd(k: int) -> int:
    k = int(k)
    if k < 1:
        k = 1
    if k % 2 == 0:
        k += 1
    return k


def _auto_ksizes(h: int, w: int) -> Tuple[int, int]:
    """
    Auto choose morphology kernel sizes based on image diagonal.
    Tuned to be "safe" for common fundus sizes (e.g., DRIVE 768x584).
    """
    diag = float(np.hypot(h, w))
    close_k = _ensure_odd(int(round(diag * 0.035)))  # ~33 for DRIVE
    open_k = _ensure_odd(int(round(diag * 0.012)))   # ~11 for DRIVE
    close_k = max(close_k, 25)
    open_k = max(open_k, 9)
    return close_k, open_k


def _morph_cleanup(mask: Array, close_ksize: int, open_ksize: int) -> Array:
    """Close gaps then open to remove specks."""
    close_ksize = _ensure_odd(close_ksize)
    open_ksize = _ensure_odd(open_ksize)

    close_k = cv.getStructuringElement(cv.MORPH_ELLIPSE, (close_ksize, close_ksize))
    open_k = cv.getStructuringElement(cv.MORPH_ELLIPSE, (open_ksize, open_ksize))

    m = cv.morphologyEx(mask, cv.MORPH_CLOSE, close_k)
    m = cv.morphologyEx(m, cv.MORPH_OPEN, open_k)
    return m


def _largest_connected_component(mask: Array) -> Array:
    """Return a binary mask (0/255) containing only the largest foreground CC."""
    m = (mask > 0).astype(np.uint8)
    num, labels, stats, _ = cv.connectedComponentsWithStats(m, connectivity=8)
    if num <= 1:
        return np.zeros_like(mask, dtype=np.uint8)

    areas = stats[1:, cv.CC_STAT_AREA]
    best_idx = 1 + int(np.argmax(areas))
    out = np.zeros_like(mask, dtype=np.uint8)
    out[labels == best_idx] = 255
    return out


def _fill_holes(mask: Array) -> Array:
    """
    Fill holes inside a binary object using flood-fill on the background.
    Input/Output are 0/255 uint8.
    More robust than using only (0,0) as seed.
    """
    m = (mask > 0).astype(np.uint8) * 255
    h, w = m.shape[:2]
    if h == 0 or w == 0:
        return m

    # find a background seed on the border
    border_coords = []
    border_coords += [(0, x) for x in range(w)]
    border_coords += [(h - 1, x) for x in range(w)]
    border_coords += [(y, 0) for y in range(h)]
    border_coords += [(y, w - 1) for y in range(h)]

    seed = None
    for (yy, xx) in border_coords:
        if m[yy, xx] == 0:
            seed = (xx, yy)  # floodFill uses (x,y)
            break
    if seed is None:
        # mask covers the whole border; nothing to flood-fill safely
        return m

    inv = cv.bitwise_not(m)
    ff = inv.copy()
    flood_mask = np.zeros((h + 2, w + 2), dtype=np.uint8)
    cv.floodFill(ff, flood_mask, seedPoint=seed, newVal=0)

    holes = (ff > 0).astype(np.uint8) * 255
    filled = cv.bitwise_or(m, holes)
    return filled


def _convex_hull(mask: Array) -> Array:
    """Return convex hull of the largest object as 0/255 mask."""
    m = (mask > 0).astype(np.uint8) * 255
    contours, _ = cv.findContours(m, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)
    if not contours:
        return np.zeros_like(m, dtype=np.uint8)

    cnt = max(contours, key=cv.contourArea)
    hull = cv.convexHull(cnt)
    out = np.zeros_like(m, dtype=np.uint8)
    cv.drawContours(out, [hull], -1, 255, thickness=cv.FILLED)
    return out


def _candidate_score(candidate_mask: Array) -> float:
    """
    Score a candidate FOV mask.
    Heuristics (good FOV):
      - large area but not the whole image
      - centered
      - low border contact
      - reasonably compact
    """
    m = (candidate_mask > 0).astype(np.uint8)
    h, w = m.shape[:2]
    area = float(m.sum())
    area_ratio = area / float(h * w)

    if area < 10:
        return -1e9

    border = np.concatenate([m[0, :], m[-1, :], m[:, 0], m[:, -1]])
    border_ratio = float(border.mean())

    ys, xs = np.where(m > 0)
    cy, cx = float(np.mean(ys)), float(np.mean(xs))
    center_dist = np.sqrt((cy - (h / 2.0)) ** 2 + (cx - (w / 2.0)) ** 2)
    center_dist_norm = center_dist / np.sqrt((h / 2.0) ** 2 + (w / 2.0) ** 2)

    circ = 0.0
    m255 = (m * 255).astype(np.uint8)
    contours, _ = cv.findContours(m255, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)
    if contours:
        cnt = max(contours, key=cv.contourArea)
        A = float(cv.contourArea(cnt))
        P = float(cv.arcLength(cnt, True))
        circ = (4.0 * np.pi * A) / (P * P + 1e-6)

    area_penalty = 0.6 if (area_ratio < 0.10 or area_ratio > 0.98) else 0.0

    score = (
        + 1.5 * area_ratio
        - 2.0 * border_ratio
        - 0.8 * center_dist_norm
        + 0.4 * circ
        - area_penalty
    )
    return float(score)


def _fit_ellipse_mask_from_contour(mask: Array, scale: float = 1.02) -> Tuple[Array, bool, str]:
    """
    Fit an ellipse to the outer contour and return an ellipse mask.
    scale > 1 expands ellipse slightly (useful to recover small border bites).
    """
    m = (mask > 0).astype(np.uint8) * 255
    h, w = m.shape[:2]
    contours, _ = cv.findContours(m, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_NONE)
    if not contours:
        return np.zeros_like(m, dtype=np.uint8), False, "no_contours"

    cnt = max(contours, key=cv.contourArea)
    if len(cnt) < 5:
        return m.copy(), False, "too_few_points_for_ellipse"

    (cx, cy), (MA, ma), angle = cv.fitEllipse(cnt)  # widths (full axis lengths)
    rx = max(1, int(round((MA * 0.5) * scale)))
    ry = max(1, int(round((ma * 0.5) * scale)))

    out = np.zeros((h, w), dtype=np.uint8)
    cv.ellipse(out, (int(round(cx)), int(round(cy))), (rx, ry), angle, 0, 360, 255, thickness=cv.FILLED)
    return out, True, "fitEllipse"

def _fit_ellipse_mask_from_ring_edges(
    g: Array,
    mask: Array,
    *,
    scale: float = 1.01,
    ring_width: int = 25,
) -> Tuple[Array, bool, str]:
    """
    Fit ellipse from Canny edges located in a thin ring around the mask border.
    This avoids bias from a truncated (bitten) filled region.
    """
    g = _to_uint8(g)
    m = (mask > 0).astype(np.uint8) * 255
    h, w = m.shape[:2]

    ring_width = max(5, int(ring_width))
    k = _ensure_odd(ring_width)
    se = cv.getStructuringElement(cv.MORPH_ELLIPSE, (k, k))

    dil = cv.dilate(m, se)
    ero = cv.erode(m, se)
    ring = cv.bitwise_and(dil, cv.bitwise_not(ero))  # border band

    # Auto Canny thresholds from median intensity INSIDE the mask
    inside = g[m > 0]
    if inside.size < 50:
        return np.zeros_like(m), False, "ring:too_few_inside_pixels"
    med = float(np.median(inside))
    lower = int(max(0, 0.66 * med))
    upper = int(min(255, 1.33 * med))

    edges = cv.Canny(g, lower, upper)
    edges = cv.bitwise_and(edges, ring)

    ys, xs = np.where(edges > 0)
    if ys.size < 80:
        return np.zeros_like(m), False, f"ring:not_enough_edge_points ({ys.size})"

    pts = np.stack([xs, ys], axis=1).astype(np.int32).reshape(-1, 1, 2)

    # fitEllipse needs >=5 points (we have plenty)
    (cx, cy), (MA, ma), angle = cv.fitEllipse(pts)

    rx = max(1, int(round((MA * 0.5) * scale)))
    ry = max(1, int(round((ma * 0.5) * scale)))

    out = np.zeros((h, w), dtype=np.uint8)
    cv.ellipse(out, (int(round(cx)), int(round(cy))), (rx, ry), angle, 0, 360, 255, thickness=cv.FILLED)
    return out, True, "ring:edge_fitEllipse"



def _should_use_ellipse(mask: Array, min_fill_ratio: float = 0.975) -> Tuple[bool, str]:
    """
    Detect the classic 'straight bite' problem:
    the shape is convex, so convex hull won't help, but area is noticeably below
    the best-fitting enclosing shape.

    We compare mask area vs minimum enclosing circle area.
    If the ratio is too low, it suggests a 'cut' happened.
    """
    m = (mask > 0).astype(np.uint8) * 255
    contours, _ = cv.findContours(m, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)
    if not contours:
        return False, "no_contours"

    cnt = max(contours, key=cv.contourArea)
    A = float(cv.contourArea(cnt))
    if A < 100:
        return False, "tiny_area"

    (x, y), r = cv.minEnclosingCircle(cnt)
    circle_area = float(np.pi * (r * r) + 1e-6)
    fill_ratio = A / circle_area

    if fill_ratio < min_fill_ratio:
        return True, f"low_fill_ratio_vs_enclosing_circle ({fill_ratio:.3f} < {min_fill_ratio:.3f})"
    return False, f"ok_fill_ratio ({fill_ratio:.3f})"


EllipseMode = Literal["off", "auto", "force"]

def _fit_ellipse_mask_from_radial_edges(
    g: Array,
    coarse_mask: Array,
    *,
    scale: float = 1.01,
    n_angles: int = 360,
    smooth_k: int = 9,
) -> Tuple[Array, bool, str]:
    """
    Fit an ellipse using boundary points detected from the ORIGINAL image (g),
    by finding the strongest outward intensity drop along radial rays.
    This is robust when the coarse mask has a 'chord' cut (Otsu/vignetting failure).
    """
    g = _to_uint8(g)
    m = (coarse_mask > 0).astype(np.uint8) * 255
    h, w = m.shape[:2]

    contours, _ = cv.findContours(m, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_NONE)
    if not contours:
        return np.zeros_like(m, dtype=np.uint8), False, "radial:no_contours"

    cnt = max(contours, key=cv.contourArea)
    if cv.contourArea(cnt) < 100:
        return np.zeros_like(m, dtype=np.uint8), False, "radial:tiny_area"

    # Use minEnclosingCircle center as a stable center guess (better than centroid when truncated)
    (cx, cy), r_guess = cv.minEnclosingCircle(cnt)
    cx = float(cx)
    cy = float(cy)
    r_guess = float(r_guess)

    if r_guess < 5:
        cx, cy = (w / 2.0), (h / 2.0)
        r_guess = 0.5 * min(h, w)

    # Smooth kernel for 1D profiles
    smooth_k = max(3, int(smooth_k))
    if smooth_k % 2 == 0:
        smooth_k += 1
    kernel = np.ones(smooth_k, dtype=np.float32) / float(smooth_k)

    pts = []

    for theta in np.linspace(0.0, 2.0 * np.pi, n_angles, endpoint=False):
        dx = float(np.cos(theta))
        dy = float(np.sin(theta))

        # Max radius until image boundary
        r_candidates = []
        if abs(dx) > 1e-6:
            r_candidates.append((0.0 - cx) / dx)
            r_candidates.append(((w - 1.0) - cx) / dx)
        if abs(dy) > 1e-6:
            r_candidates.append((0.0 - cy) / dy)
            r_candidates.append(((h - 1.0) - cy) / dy)

        r_candidates = [rr for rr in r_candidates if rr > 0]
        if not r_candidates:
            continue
        rmax = min(r_candidates)
        if rmax < 5:
            continue

        # Search window around guessed radius
        r_start = int(max(5, 0.55 * r_guess))
        r_end = int(min(rmax - 2, 1.25 * r_guess))
        if r_end <= r_start + 4:
            r_start = 1
            r_end = int(rmax - 2)

        rr = np.arange(r_start, r_end + 1, dtype=np.int32)
        xs = np.clip(np.rint(cx + rr * dx).astype(np.int32), 0, w - 1)
        ys = np.clip(np.rint(cy + rr * dy).astype(np.int32), 0, h - 1)

        prof = g[ys, xs].astype(np.float32)
        if prof.size < 6:
            continue

        # Smooth the profile to reduce vessel/noise spikes
        prof_s = np.convolve(prof, kernel, mode="same")

        # We want the strongest OUTWARD drop: inside(bright) -> outside(dark)
        drops = prof_s[:-1] - prof_s[1:]  # positive when going darker
        idx = int(np.argmax(drops))
        r_edge = int(rr[idx])

        x = int(np.clip(round(cx + r_edge * dx), 0, w - 1))
        y = int(np.clip(round(cy + r_edge * dy), 0, h - 1))
        pts.append([x, y])

    if len(pts) < 5:
        return np.zeros_like(m, dtype=np.uint8), False, "radial:too_few_points"

    pts_np = np.array(pts, dtype=np.int32).reshape(-1, 1, 2)
    (ecx, ecy), (MA, ma), angle = cv.fitEllipse(pts_np)

    rx = max(1, int(round((MA * 0.5) * scale)))
    ry = max(1, int(round((ma * 0.5) * scale)))

    out = np.zeros((h, w), dtype=np.uint8)
    cv.ellipse(
        out,
        (int(round(ecx)), int(round(ecy))),
        (rx, ry),
        angle,
        0,
        360,
        255,
        thickness=cv.FILLED,
    )
    return out, True, "radial:edge_drop_fitEllipse"



def compute_fov_mask(
    img_or_path: Union[str, Array],
    *,
    blur_ksize: int = 7,
    blur_kind: str = "median",     # "median" or "gaussian"
    close_ksize: Optional[int] = None,  # None => auto
    open_ksize: Optional[int] = None,   # None => auto
    do_hole_fill: bool = True,
    do_convex_hull: bool = True,
    ellipse_mode: EllipseMode = "auto",  # off / auto / force
    ellipse_scale: float = 1.02,         # slightly enlarge to recover small bites
    ellipse_min_fill_ratio: float = 0.975,
    return_debug: bool = False,
) -> Union[Array, Tuple[Array, FOVMaskDebug]]:
    """
    Compute a clean binary Field-Of-View (FOV) mask (0/255 uint8) for a fundus image.

    Fixes supported (exactly what we discussed):
      1) stronger closing (auto close/open sizes are bigger by default)
      2) convex hull (optional)
      3) ellipse fitting (robust for convex 'bites' that hull cannot fix)

    Returns:
      mask (uint8 0/255), and optionally debug object.
    """
    # Load if needed
    if isinstance(img_or_path, str):
        img = cv.imread(img_or_path, cv.IMREAD_UNCHANGED)
        if img is None:
            raise FileNotFoundError(f"Could not read image from path: {img_or_path}")
    else:
        img = img_or_path

    g = _to_gray_or_green(img)
    h, w = g.shape[:2]

    # Auto kernel sizes if not provided
    if close_ksize is None or open_ksize is None:
        auto_close, auto_open = _auto_ksizes(h, w)
        if close_ksize is None:
            close_ksize = auto_close
        if open_ksize is None:
            open_ksize = auto_open

    # Blur
    blur_ksize = _ensure_odd(blur_ksize)
    if blur_kind.lower() == "median":
        blurred = cv.medianBlur(g, blur_ksize)
    elif blur_kind.lower() == "gaussian":
        blurred = cv.GaussianBlur(g, (blur_ksize, blur_ksize), 0)
    else:
        raise ValueError("blur_kind must be 'median' or 'gaussian'.")
    g_corr = _flatfield_for_otsu(blurred)
    # Otsu threshold
    _, otsu = cv.threshold(g_corr, 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU)

    # Two candidates: otsu foreground or inverted foreground
    cand_a = otsu
    cand_b = cv.bitwise_not(otsu)

    # Morph cleanup each candidate (this is where close fixes bites)
    cand_a_m = _morph_cleanup(cand_a, close_ksize=close_ksize, open_ksize=open_ksize)
    cand_b_m = _morph_cleanup(cand_b, close_ksize=close_ksize, open_ksize=open_ksize)

    # Keep largest CC
    cand_a_l = _largest_connected_component(cand_a_m)
    cand_b_l = _largest_connected_component(cand_b_m)

    # Score both
    score_a = _candidate_score(cand_a_l)
    score_b = _candidate_score(cand_b_l)

    if score_b > score_a:
        chosen = cand_b_l
        chosen_inverted = True
        scores = {"normal": score_a, "inverted": score_b}
        after_morph = cand_b_m
    else:
        chosen = cand_a_l
        chosen_inverted = False
        scores = {"normal": score_a, "inverted": score_b}
        after_morph = cand_a_m

    filled = _fill_holes(chosen) if do_hole_fill else chosen.copy()
    hull = _convex_hull(filled) if do_convex_hull else filled.copy()

    # Ellipse handling (robust for convex straight "bites")
    ellipse_used = False
    ellipse_reason = "off"
    ellipse_mask = np.zeros_like(hull)

    if ellipse_mode == "force":
        ellipse_mask, ellipse_used, ellipse_reason = _fit_ellipse_mask_from_contour(hull, scale=ellipse_scale)
        final = ellipse_mask
    elif ellipse_mode == "auto":
        need, why = _should_use_ellipse(hull, min_fill_ratio=ellipse_min_fill_ratio)
        ellipse_reason = why
        if need:
            # NEW: fit from real image boundary (robust to the 'chord' failure)
            ellipse_mask, ellipse_used, fit_why = _fit_ellipse_mask_from_ring_edges(
                g_corr, hull, scale=ellipse_scale, ring_width=25
            )
            if ellipse_used:
                ellipse_reason = f"{ellipse_reason} | {fit_why}"
                final = ellipse_mask
            else:
                # fallback to your old contour-based ellipse
                ellipse_mask, ellipse_used, fit_why2 = _fit_ellipse_mask_from_contour(hull, scale=ellipse_scale)
                ellipse_reason = f"{ellipse_reason} | fallback:{fit_why2}"
                final = ellipse_mask if ellipse_used else hull
        else:
            final = hull

    else:  # "off"
        final = hull

    final = (final > 0).astype(np.uint8) * 255

    if not return_debug:
        return final

    dbg = FOVMaskDebug(
        green_or_gray=g,
        blurred=blurred,
        otsu=otsu,
        candidate_chosen=chosen,
        after_morph=after_morph,
        largest_cc=chosen,
        filled=filled,
        convex_hull=hull,
        ellipse_mask=ellipse_mask,
        final=final,
        chosen_inverted=chosen_inverted,
        scores=scores,
        ellipse_used=ellipse_used,
        ellipse_reason=ellipse_reason,
    )
    return final, dbg

%%writefile test_fov_mask.py
import numpy as np
import cv2 as cv

from fov_mask import compute_fov_mask


def _iou(a: np.ndarray, b: np.ndarray) -> float:
    a = (a > 0)
    b = (b > 0)
    inter = np.logical_and(a, b).sum()
    union = np.logical_or(a, b).sum()
    return float(inter) / float(union + 1e-9)


def test_mask_is_binary_uint8():
    img = np.zeros((256, 256, 3), dtype=np.uint8)
    cv.circle(img, (128, 128), 90, (40, 180, 40), thickness=-1)  # green-ish disk
    mask = compute_fov_mask(img, do_hole_fill=True, do_convex_hull=True)

    assert mask.dtype == np.uint8
    vals = set(np.unique(mask).tolist())
    assert vals.issubset({0, 255})
    assert 0 in vals and 255 in vals


def test_circle_fov_high_iou_with_noise_and_holes():
    rng = np.random.default_rng(0)
    h, w = 512, 512
    img = np.zeros((h, w, 3), dtype=np.uint8)

    # Ideal circle FOV
    gt = np.zeros((h, w), dtype=np.uint8)
    cv.circle(gt, (w // 2, h // 2), 200, 255, thickness=-1)

    # Create fundus-like content inside the FOV
    base = np.zeros((h, w), dtype=np.uint8)
    base[gt > 0] = 150
    noise = rng.normal(0, 12, size=(h, w)).astype(np.float32)
    noisy = np.clip(base.astype(np.float32) + noise, 0, 255).astype(np.uint8)

    # Add holes inside the FOV (simulate gaps)
    holes = gt.copy()
    for _ in range(40):
        x = int(rng.integers(w // 2 - 150, w // 2 + 150))
        y = int(rng.integers(h // 2 - 150, h // 2 + 150))
        r = int(rng.integers(6, 18))
        cv.circle(holes, (x, y), r, 0, thickness=-1)

    noisy[holes == 0] = 0

    # Add random bright specks outside FOV
    for _ in range(300):
        x = int(rng.integers(0, w))
        y = int(rng.integers(0, h))
        if gt[y, x] == 0:
            noisy[y, x] = 255

    # Put into green channel (like real fundus)
    img[:, :, 1] = noisy

    mask = compute_fov_mask(
        img,
        blur_kind="median",
        blur_ksize=7,
        close_ksize=25,
        open_ksize=9,
        do_hole_fill=True,
        do_convex_hull=True,
    )

    score = _iou(mask, gt)
    assert score > 0.95, f"IoU too low: {score}"


def test_ellipse_fov_detected():
    rng = np.random.default_rng(1)
    h, w = 480, 640
    img = np.zeros((h, w, 3), dtype=np.uint8)

    gt = np.zeros((h, w), dtype=np.uint8)
    cv.ellipse(gt, (w // 2, h // 2), (240, 170), 0, 0, 360, 255, thickness=-1)

    base = np.zeros((h, w), dtype=np.uint8)
    base[gt > 0] = 140
    noise = rng.normal(0, 10, size=(h, w)).astype(np.float32)
    g = np.clip(base.astype(np.float32) + noise, 0, 255).astype(np.uint8)

    img[:, :, 1] = g

    mask = compute_fov_mask(
        img,
        blur_kind="gaussian",
        blur_ksize=7,
        close_ksize=31,
        open_ksize=11,
        do_hole_fill=True,
        do_convex_hull=True,
    )

    score = _iou(mask, gt)
    assert score > 0.93, f"IoU too low on ellipse: {score}"


def test_works_on_grayscale_input():
    h, w = 300, 300
    gray = np.zeros((h, w), dtype=np.uint8)
    cv.circle(gray, (150, 150), 110, 160, thickness=-1)

    mask = compute_fov_mask(gray, do_hole_fill=True, do_convex_hull=True)
    assert mask.shape == gray.shape
    assert mask.dtype == np.uint8
    assert set(np.unique(mask).tolist()).issubset({0, 255})




    !pip install opencv-python numpy pytest matplotlib


import os
from pathlib import Path
import cv2 as cv

img_path = Path("images/input/4.png")

print("cwd =", os.getcwd())
print("relative exists? =", img_path.exists())
print("absolute path =", img_path.resolve())
print("absolute exists? =", img_path.resolve().exists())

# OpenCV check
abs_path = str(img_path.resolve())
print("cv.haveImageReader =", cv.haveImageReader(abs_path))
img = cv.imread(abs_path, cv.IMREAD_UNCHANGED)
print("cv.imread is None? =", img is None)





from pathlib import Path
import os

def find_project_root(start: Path | None = None) -> Path:
    p = (start or Path.cwd()).resolve()
    for _ in range(25):
        if (p / "images" / "input").exists():
            return p
        if p.parent == p:
            break
        p = p.parent
    raise FileNotFoundError("Couldn't find a folder containing images/input")

ROOT = find_project_root()
print("cwd =", os.getcwd())
print("ROOT =", ROOT)



import cv2 as cv

img_path = ROOT / "images" / "input" / "4.png"
img = cv.imread(str(img_path), cv.IMREAD_UNCHANGED)
print("img is None?", img is None)




import cv2 as cv
from matplotlib import pyplot as plt
from pathlib import Path
import os

from fov_mask import compute_fov_mask

def find_project_root(start: Path | None = None) -> Path:
    p = (start or Path.cwd()).resolve()
    for _ in range(25):
        if (p / "images" / "input").exists():
            return p
        if p.parent == p:
            break
        p = p.parent
    raise FileNotFoundError("Couldn't find a folder containing images/input")

ROOT = find_project_root()  # <- keep this, DO NOT use .parent
print("cwd =", Path.cwd().resolve())
print("ROOT =", ROOT)

img_path = ROOT / "images" / "input" / "14.png"
print("img_path =", img_path)
print("exists? =", img_path.exists())

img = cv.imread(str(img_path), cv.IMREAD_UNCHANGED)
if img is None:
    raise FileNotFoundError(f"OpenCV could not read: {img_path}")

mask, dbg = compute_fov_mask(
    img,
    close_ksize=21,
    open_ksize=11,
    do_convex_hull=True,
    ellipse_mode="auto",
    ellipse_scale=1.01,
    return_debug=True
)

plt.figure(figsize=(18,4))
plt.subplot(1,5,1); plt.title("Green/Gray");  plt.imshow(dbg.green_or_gray, cmap="gray"); plt.axis("off")
plt.subplot(1,5,2); plt.title("Otsu");        plt.imshow(dbg.otsu, cmap="gray");          plt.axis("off")
plt.subplot(1,5,3); plt.title("Largest CC");  plt.imshow(dbg.largest_cc, cmap="gray");    plt.axis("off")
plt.subplot(1,5,4); plt.title("Convex hull"); plt.imshow(dbg.convex_hull, cmap="gray");   plt.axis("off")
plt.subplot(1,5,5); plt.title("Final");       plt.imshow(mask, cmap="gray");              plt.axis("off")
plt.show()

print("Chosen inverted:", dbg.chosen_inverted)
print("Scores:", dbg.scores)
print("Ellipse used:", dbg.ellipse_used)
print("Ellipse reason:", dbg.ellipse_reason)



















%%writefile vessel_pipeline_e.py
from __future__ import annotations

from dataclasses import dataclass
from typing import Dict, List, Optional, Tuple, Union

import numpy as np
import cv2 as cv

from fov_mask import compute_fov_mask

Array = np.ndarray


# -----------------------------
# Debug helpers
# -----------------------------
def _dbg(verbose: bool, *args):
    if verbose:
        print(*args)


def _to_uint8(x: Array) -> Array:
    if x.dtype == np.uint8:
        return x
    xf = x.astype(np.float32)
    xf -= xf.min()
    den = float(xf.max() - xf.min())
    if den < 1e-6:
        den = 1.0
    y = (255.0 * (xf / den)).clip(0, 255).astype(np.uint8)
    return y


def _get_green_or_gray(img: Array) -> Array:
    if img.ndim == 2:
        return _to_uint8(img)
    if img.ndim == 3 and img.shape[2] >= 3:
        # OpenCV loads BGR; green channel usually best for vessels
        return _to_uint8(img[:, :, 1])
    raise ValueError(f"Unsupported image shape: {img.shape}")


def _masked_otsu_threshold(values_u8: Array) -> int:
    """
    Compute Otsu threshold from a 1D uint8 array of values (already masked).
    """
    if values_u8.size == 0:
        return 128
    hist = np.bincount(values_u8.ravel(), minlength=256).astype(np.float64)
    total = float(values_u8.size)

    sum_total = float(np.dot(np.arange(256), hist))
    sum_b = 0.0
    w_b = 0.0
    w_f = 0.0

    var_max = -1.0
    thr = 128

    for t in range(256):
        w_b += hist[t]
        if w_b <= 0:
            continue
        w_f = total - w_b
        if w_f <= 0:
            break

        sum_b += float(t * hist[t])
        m_b = sum_b / w_b
        m_f = (sum_total - sum_b) / w_f

        var_between = w_b * w_f * (m_b - m_f) * (m_b - m_f)
        if var_between > var_max:
            var_max = var_between
            thr = t

    return int(thr)


def _line_kernel(length: int, angle_deg: float) -> Array:
    """
    Create a 2D line structuring element of given odd length and orientation.
    """
    length = int(length)
    if length < 3:
        length = 3
    if length % 2 == 0:
        length += 1

    k = np.zeros((length, length), dtype=np.uint8)
    c = length // 2

    # Endpoint vector
    rad = np.deg2rad(angle_deg)
    dx = int(round((length // 2) * np.cos(rad)))
    dy = int(round((length // 2) * np.sin(rad)))

    x1, y1 = c - dx, c - dy
    x2, y2 = c + dx, c + dy

    cv.line(k, (x1, y1), (x2, y2), color=1, thickness=1)
    return k


def _retinex_bilateral(gray_u8: Array, *, d: int = 5, sigma_color: float = 35.0, sigma_space: float = 35.0) -> Array:
    """
    Retinex-style illumination correction inspired by the paper:
      R(x) = log(I+1) - log(L+1), where L is edge-preserving (bilateral) smooth.
    Output: uint8 in [0,255].
    """
    I = gray_u8.astype(np.float32)
    L = cv.bilateralFilter(gray_u8, d=d, sigmaColor=float(sigma_color), sigmaSpace=float(sigma_space)).astype(np.float32)

    R = np.log1p(I) - np.log1p(L)
    R = _to_uint8(R)
    return R


def _clahe(gray_u8: Array, clip_limit: float = 2.0, tile_grid_size: Tuple[int, int] = (8, 8)) -> Array:
    clahe = cv.createCLAHE(clipLimit=float(clip_limit), tileGridSize=tile_grid_size)
    return clahe.apply(gray_u8)


def _multiscale_multiorient_blackhat(
    gray_u8: Array,
    *,
    lengths: List[int],
    angles_deg: List[float],
    blur_ksize: int = 3,
) -> Array:
    """
    Vesselness-like map using multi-scale, multi-orientation morphological BLACKHAT.
    Dark vessels on brighter background -> blackhat highlights them.
    """
    if blur_ksize and blur_ksize >= 3:
        if blur_ksize % 2 == 0:
            blur_ksize += 1
        g = cv.GaussianBlur(gray_u8, (blur_ksize, blur_ksize), 0)
    else:
        g = gray_u8

    best = np.zeros_like(g, dtype=np.uint8)

    for L in lengths:
        for a in angles_deg:
            k = _line_kernel(L, a)
            bh = cv.morphologyEx(g, cv.MORPH_BLACKHAT, k)
            best = cv.max(best, bh)

    return best


@dataclass
class CCFilterStats:
    kept: int
    removed: int
    total: int
    removed_reasons: Dict[str, int]


def _component_shape_metrics(component_mask_u8: Array) -> Dict[str, float]:
    """
    Compute basic shape descriptors for a single component mask (0/1 or 0/255).
    Returns: area, perimeter, circularity, elongation, bbox_ar, extent
    """
    m = (component_mask_u8 > 0).astype(np.uint8)
    area = float(m.sum())

    contours, _ = cv.findContours(m, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_NONE)
    if not contours:
        return {
            "area": area,
            "perimeter": 0.0,
            "circularity": 1.0,
            "elongation": 1.0,
            "bbox_ar": 1.0,
            "extent": 1.0,
        }

    cnt = max(contours, key=cv.contourArea)
    per = float(cv.arcLength(cnt, True))

    # circularity: 1 for circle, lower for elongated
    circ = (4.0 * np.pi * area) / (per * per + 1e-6)

    x, y, w, h = cv.boundingRect(cnt)
    bbox_ar = float(max(w, h)) / float(min(w, h) + 1e-6)
    extent = float(area) / float(w * h + 1e-6)

    # elongation via PCA on coordinates
    ys, xs = np.where(m > 0)
    if xs.size < 5:
        elong = bbox_ar
    else:
        pts = np.stack([xs.astype(np.float32), ys.astype(np.float32)], axis=1)
        pts -= pts.mean(axis=0, keepdims=True)
        cov = (pts.T @ pts) / float(max(1, pts.shape[0] - 1))
        evals, _ = np.linalg.eigh(cov)
        evals = np.sort(evals)  # ascending
        # major/minor axis ratio
        elong = float(np.sqrt((evals[1] + 1e-9) / (evals[0] + 1e-9)))

    return {
        "area": float(area),
        "perimeter": float(per),
        "circularity": float(circ),
        "elongation": float(elong),
        "bbox_ar": float(bbox_ar),
        "extent": float(extent),
    }


def _filter_connected_components(
    bin_mask_u8: Array,
    *,
    min_area: int = 30,
    min_area_if_elongated: int = 15,
    min_elongation: float = 2.2,
    max_circularity: float = 0.38,
    max_extent_blob: float = 0.70,
    connectivity: int = 8,
    verbose: bool = False,
) -> Tuple[Array, CCFilterStats]:
    """
    Pipeline E core: CC filtering as structural enforcement.
    We REMOVE components that are:
      - too small
      - too round/compact (blob-like): high circularity + low elongation OR high extent
    """
    m = (bin_mask_u8 > 0).astype(np.uint8)
    num, labels, stats, _ = cv.connectedComponentsWithStats(m, connectivity=connectivity)

    removed_reasons: Dict[str, int] = {}
    out = np.zeros_like(m, dtype=np.uint8)

    total_cc = max(0, num - 1)
    kept = 0
    removed = 0

    _dbg(verbose, f"[CC] total components (excluding bg) = {total_cc}")

    for cc_id in range(1, num):
        area = int(stats[cc_id, cv.CC_STAT_AREA])
        cc_mask = (labels == cc_id).astype(np.uint8)

        metrics = _component_shape_metrics(cc_mask)

        # Rules:
        # 1) tiny noise
        if area < int(min_area_if_elongated):
            removed += 1
            removed_reasons["too_small_hard"] = removed_reasons.get("too_small_hard", 0) + 1
            continue

        # 2) small but not elongated enough
        if area < int(min_area) and metrics["elongation"] < float(min_elongation):
            removed += 1
            removed_reasons["too_small_not_elongated"] = removed_reasons.get("too_small_not_elongated", 0) + 1
            continue

        # 3) blob-like: round + not elongated
        if metrics["circularity"] > float(max_circularity) and metrics["elongation"] < float(min_elongation):
            removed += 1
            removed_reasons["too_round_compact"] = removed_reasons.get("too_round_compact", 0) + 1
            continue

        # 4) very “filled” bbox -> tends to be lesions/blobs rather than line structures
        if metrics["extent"] > float(max_extent_blob) and metrics["elongation"] < float(min_elongation):
            removed += 1
            removed_reasons["high_extent_blob"] = removed_reasons.get("high_extent_blob", 0) + 1
            continue

        # Keep
        out[labels == cc_id] = 1
        kept += 1

    out_u8 = (out * 255).astype(np.uint8)

    _dbg(
        verbose,
        f"[CC] kept={kept} removed={removed} total={total_cc} reasons={removed_reasons}"
    )

    return out_u8, CCFilterStats(kept=kept, removed=removed, total=total_cc, removed_reasons=removed_reasons)


# -----------------------------
# Pipeline E main API
# -----------------------------
def vessel_segmentation(
    input_image: Union[str, Array],
    *,
    verbose: bool = False,
    # Upstream segmenter knobs
    retinex_d: int = 5,
    retinex_sigma_color: float = 35.0,
    retinex_sigma_space: float = 35.0,
    clahe_clip: float = 2.2,
    clahe_tile: Tuple[int, int] = (8, 8),
    bh_lengths: Tuple[int, ...] = (9, 13, 17),
    bh_angle_step_deg: int = 15,
    bh_blur_ksize: int = 3,
    # Binarization knobs
    thr_offset: int = 0,  # shift Otsu a bit (+ -> stricter, - -> more vessels)
    post_open_ksize: int = 3,
    post_close_ksize: int = 3,
    # CC filter knobs (Pipeline E core)
    cc_min_area: int = 30,
    cc_min_area_if_elongated: int = 15,
    cc_min_elongation: float = 2.2,
    cc_max_circularity: float = 0.38,
    cc_max_extent_blob: float = 0.70,
) -> Array:
    """
    Pipeline E:
      Upstream unsupervised segmenter (Retinex-ish + multi-orient black-hat + threshold)
      THEN Connected Components filtering as structural enforcement.

    Returns:
      segmented_image: uint8 0/255 (same HxW as input)
    """
    # Load
    if isinstance(input_image, str):
        img = cv.imread(input_image, cv.IMREAD_UNCHANGED)
        if img is None:
            raise FileNotFoundError(f"Could not read image: {input_image}")
    else:
        img = input_image

    # FOV
    fov = compute_fov_mask(img)
    fov_bool = (fov > 0)
    _dbg(verbose, f"[E] FOV coverage = {fov_bool.mean():.3f}")

    g = _get_green_or_gray(img)

    # Retinex-style correction
    r = _retinex_bilateral(
        g,
        d=retinex_d,
        sigma_color=retinex_sigma_color,
        sigma_space=retinex_sigma_space,
    )
    _dbg(verbose, f"[E] Retinex: min={int(r.min())} max={int(r.max())} mean={float(r.mean()):.2f}")

    # Local contrast
    c = _clahe(r, clip_limit=clahe_clip, tile_grid_size=clahe_tile)
    _dbg(verbose, f"[E] CLAHE: min={int(c.min())} max={int(c.max())} mean={float(c.mean()):.2f}")

    # Vesselness-ish via multiscale multi-orientation black-hat
    angles = list(np.arange(0, 180, int(bh_angle_step_deg), dtype=np.int32).tolist())
    vesselness = _multiscale_multiorient_blackhat(
        c,
        lengths=list(map(int, bh_lengths)),
        angles_deg=list(map(float, angles)),
        blur_ksize=int(bh_blur_ksize),
    )

    # Normalize inside FOV (for stable thresholding)
    v = vesselness.copy()
    v[~fov_bool] = 0

    vals = v[fov_bool].astype(np.uint8)
    thr = _masked_otsu_threshold(vals)
    thr = int(np.clip(thr + int(thr_offset), 0, 255))

    p50 = int(np.percentile(vals, 50)) if vals.size else 0
    p90 = int(np.percentile(vals, 90)) if vals.size else 0
    _dbg(verbose, f"[E] Vesselness: p50={p50} p90={p90} otsu_thr={thr} (offset={thr_offset})")

    initial = (v > thr).astype(np.uint8) * 255
    initial[~fov_bool] = 0

    _dbg(verbose, f"[E] Initial bin: fg_frac={float((initial>0).mean()):.4f}")

    # Light morphology to reduce specks & reconnect micro-gaps (still upstream)
    if post_open_ksize and post_open_ksize >= 3:
        k = cv.getStructuringElement(cv.MORPH_ELLIPSE, (post_open_ksize, post_open_ksize))
        initial = cv.morphologyEx(initial, cv.MORPH_OPEN, k)

    if post_close_ksize and post_close_ksize >= 3:
        k = cv.getStructuringElement(cv.MORPH_ELLIPSE, (post_close_ksize, post_close_ksize))
        initial = cv.morphologyEx(initial, cv.MORPH_CLOSE, k)

    _dbg(verbose, f"[E] After morph: fg_frac={float((initial>0).mean()):.4f}")

    # -----------------------------
    # Pipeline E KEY step: CC filtering
    # -----------------------------
    filtered, cc_stats = _filter_connected_components(
        initial,
        min_area=cc_min_area,
        min_area_if_elongated=cc_min_area_if_elongated,
        min_elongation=cc_min_elongation,
        max_circularity=cc_max_circularity,
        max_extent_blob=cc_max_extent_blob,
        connectivity=8,
        verbose=verbose,
    )

    # Optional final gentle reconnect (kept minimal to not bloat vessels)
    # (If you want, you can raise post_close_ksize instead of doing more here.)
    filtered[~fov_bool] = 0
    filtered = (filtered > 0).astype(np.uint8) * 255

    _dbg(verbose, f"[E] Final: fg_frac={float((filtered>0).mean()):.4f} dtype={filtered.dtype} unique={np.unique(filtered)[:5]}")

    return filtered


















%%writefile test_pipeline_e.py
import numpy as np
import cv2 as cv

from vessel_pipeline_e import vessel_segmentation


def _make_synth_fundus(h=256, w=256, seed=0):
    rng = np.random.default_rng(seed)

    img = np.zeros((h, w, 3), dtype=np.uint8)

    # FOV disk (brighter interior)
    fov = np.zeros((h, w), dtype=np.uint8)
    cv.circle(fov, (w // 2, h // 2), int(min(h, w) * 0.42), 255, thickness=-1)

    base = np.zeros((h, w), dtype=np.uint8)
    base[fov > 0] = 160

    noise = rng.normal(0, 8, size=(h, w)).astype(np.float32)
    g = np.clip(base.astype(np.float32) + noise, 0, 255).astype(np.uint8)

    # Draw vessel-like dark lines inside FOV
    for a in [10, 35, 75, 110, 150]:
        x0 = int(w * 0.2)
        y0 = int(h * 0.5)
        x1 = int(w * 0.8)
        y1 = int(h * 0.5)
        M = cv.getRotationMatrix2D((w // 2, h // 2), a, 1.0)
        pts = np.array([[x0, y0], [x1, y1]], dtype=np.float32)
        pts = cv.transform(np.array([pts]), M)[0].astype(int)
        cv.line(g, tuple(pts[0]), tuple(pts[1]), color=60, thickness=2)

    # Add a dark round blob (should be removed by CC filtering)
    blob_center = (int(w * 0.70), int(h * 0.35))
    cv.circle(g, blob_center, 10, 50, thickness=-1)

    # Apply FOV cutoff
    g[fov == 0] = 0

    img[:, :, 1] = g  # put in green channel
    return img, blob_center


def test_pipeline_e_output_is_binary_uint8_and_shape(tmp_path):
    img, _ = _make_synth_fundus()
    p = tmp_path / "synth.png"
    assert cv.imwrite(str(p), img)

    out = vessel_segmentation(str(p), verbose=False)
    assert out.dtype == np.uint8
    assert out.shape[:2] == img.shape[:2]
    vals = set(np.unique(out).tolist())
    assert vals.issubset({0, 255})


def test_pipeline_e_removes_round_blob_keeps_lines(tmp_path):
    img, blob_center = _make_synth_fundus()
    p = tmp_path / "synth.png"
    assert cv.imwrite(str(p), img)

    out = vessel_segmentation(
        str(p),
        verbose=False,
        # slightly lenient threshold so both lines+blob get detected upstream,
        # then CC filter must remove blob
        thr_offset=-5,
        cc_min_area=25,
        cc_min_area_if_elongated=12,
        cc_min_elongation=2.0,
        cc_max_circularity=0.42,
        cc_max_extent_blob=0.72,
    )

    # Check blob area mostly removed
    bx, by = blob_center
    patch = out[max(0, by-12):by+13, max(0, bx-12):bx+13]
    blob_fg = float((patch > 0).mean())
    assert blob_fg < 0.35, f"Blob not removed enough (fg_frac={blob_fg:.3f})"

    # Check that we still have some vessels detected overall
    fg_frac = float((out > 0).mean())
    assert fg_frac > 0.003, f"Too few vessel pixels detected (fg_frac={fg_frac:.4f})"


def test_pipeline_e_verbose_runs(tmp_path, capsys):
    img, _ = _make_synth_fundus()
    p = tmp_path / "synth.png"
    assert cv.imwrite(str(p), img)

    out = vessel_segmentation(str(p), verbose=True)
    captured = capsys.readouterr().out
    assert out is not None
    assert "[E]" in captured or "[CC]" in captured
















import os
from pathlib import Path
import cv2 as cv
from matplotlib import pyplot as plt

from vessel_pipeline_e import vessel_segmentation  # <- Pipeline E

def find_project_root(start: Path | None = None) -> Path:
    p = (start or Path.cwd()).resolve()
    for _ in range(25):
        if (p / "images" / "input").exists():
            return p
        if p.parent == p:
            break
        p = p.parent
    raise FileNotFoundError("Couldn't find a folder containing images/input")

# Dataset paths (project-local)
ROOT = find_project_root()
img_path = ROOT / "images" / "input"
gt_path = ROOT / "images" / "gt"

print("ROOT:", ROOT)
print("Input dir:", img_path, "| exists:", img_path.exists())
print("GT dir:", gt_path, "| exists:", gt_path.exists())

def single_IoU(img_name: str) -> float:
    input_img = img_path / img_name
    if not input_img.exists():
        raise FileNotFoundError(f"Could not find input image: {input_img}")

    obtained = vessel_segmentation(str(input_img), verbose=False)

    target_img = gt_path / img_name
    solution = cv.imread(str(target_img), cv.IMREAD_GRAYSCALE)
    if solution is None:
        raise FileNotFoundError(f"Could not read ground-truth: {target_img}")

    # ensure binary 0/255
    obtained = (obtained > 0).astype("uint8") * 255
    solution = (solution > 0).astype("uint8") * 255

    print(f"[DBG] {img_name} | obtained shape={obtained.shape} unique={sorted(set(obtained.ravel().tolist()))[:5]}")
    print(f"[DBG] {img_name} | solution shape={solution.shape} unique={sorted(set(solution.ravel().tolist()))[:5]}")

    plt.imshow(obtained, cmap="gray")
    plt.title(f"Obtained: {img_name}")
    plt.axis("off")
    plt.show()

    intersectionAB = cv.countNonZero(cv.bitwise_and(obtained, solution))
    unionAB = cv.countNonZero(cv.bitwise_or(obtained, solution))
    score = float(intersectionAB) / float(unionAB + 1e-9)

    print(f"Image {img_name} - IoU={score:.6f}")
    return score

# Evaluate all images
meanIoU = 0.0
imgs = sorted([p.name for p in img_path.iterdir() if p.suffix.lower() == ".png"])
print("Images:", imgs)

for img in imgs:
    meanIoU += single_IoU(img)

meanIoU /= max(1, len(imgs))
print("------------------------------------")
print(f"Mean IoU={meanIoU:.6f}")
